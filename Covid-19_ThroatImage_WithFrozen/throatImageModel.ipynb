{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "throatImage.ipynb",
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "275_i4NTXXQa",
        "colab_type": "code",
        "outputId": "aed2ad3a-3a6c-4c47-f211-5912d8c340ec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 120
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iBsWzvo1HsoU",
        "colab_type": "code",
        "outputId": "cb906175-0f19-4909-d4ba-09eadd00f46a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "ls"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[0m\u001b[01;34mdrive\u001b[0m/  \u001b[01;34msample_data\u001b[0m/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8-6fKi0HXndG",
        "colab_type": "code",
        "outputId": "61fb4138-59df-45ec-f329-7c5e5f3ce24b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "cd drive/My\\ Drive/cronathroat/WithoutRevist_Fullaugumented/"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/cronathroat/WithoutRevist_Fullaugumented\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TJvN4_J32x2e",
        "colab_type": "code",
        "outputId": "d132d3cb-bde9-44d4-b3ed-4b1c9bbb28bc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "pwd"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/My Drive/cronathroat/WithoutRevist_Fullaugumented'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z21-NJzXXqsT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import division, print_function, absolute_import\n",
        "import tensorflow as tf\n",
        "import os\n",
        "import random\n",
        "from skimage import io, transform\n",
        "import numpy as np\n",
        "from skimage.color import rgb2gray\n",
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sxKQokk8XzEI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trainingData = pd.read_csv(\"train.csv\")\n",
        "\n",
        "testingData = pd.read_csv(\"test.csv\")\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mIb8gWPiYP75",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from PIL import Image\n",
        "def readData(df, path):\n",
        "    \n",
        "    imageArray  = [] \n",
        "    labelArray = []\n",
        "        \n",
        "    for index, row in df.iterrows():\n",
        "        imageFileName = row['Name']\n",
        "        label = row['Label']\n",
        "        labelArray.append(label)\n",
        "\n",
        "        try:\n",
        "            img = Image.open(path+imageFileName)\n",
        "            #img = io.imread(path+imageFileName, plugin='matplotlib')\n",
        "            #img = rgb2gray(img)\n",
        "            #img = img.convert('RGB')\n",
        "            img = transform.resize(np.array(img), (224, 224),anti_aliasing=True)#height,width\n",
        "            #io.imshow(img) \n",
        "            #io.show()\n",
        "            #return\n",
        "            #img = img.reshape(img.shape[0],img.shape[1],1)\n",
        "            imageArray.append(img)\n",
        "            #Normalizing image data\n",
        "            \n",
        "        \n",
        "        except Exception as e:\n",
        "            print(e)\n",
        "            pass\n",
        "    return imageArray, labelArray"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ceWkqIO3YNub",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_X, train_Y = readData(trainingData, \"./train/\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ogISIwBefdOD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_X, test_Y = readData(testingData, \"./test/\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SxHb5jMdIicd",
        "colab_type": "code",
        "outputId": "ca6bb66b-2f15-4487-ae09-3669a532aaab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "train_X[0].shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(224, 224, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "crHm2qVhfwCP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learningRate = 0.001\n",
        "dropOut = 0.1\n",
        "\n",
        "height = 224\n",
        "width = 224\n",
        "num_classes = 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gkGwk7DNlcuy",
        "colab_type": "code",
        "outputId": "566a51f9-e912-446c-f58f-7d689ad48647",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        }
      },
      "source": [
        "tf.compat.v1.disable_eager_execution()\n",
        "\n",
        "tf.compat.v1.reset_default_graph()\n",
        "\n",
        "\n",
        "\n",
        "inputImage = tf.compat.v1.placeholder(tf.float32, shape=[None, height, width,3], name=\"X\")\n",
        "#label = tf.compat.v1.placeholder(tf.float32, shape=[None], name=\"label\")\n",
        "label = tf.compat.v1.placeholder(tf.float32, shape=[None], name=\"label\")\n",
        "l_rate = tf.compat.v1.placeholder(tf.float32, name = \"learningRate\")\n",
        "d_out = tf.compat.v1.placeholder(tf.float32, name = \"dropOut\")\n",
        "\n",
        "\n",
        "regularizer = tf.keras.regularizers.l2()\n",
        "\n",
        "conv2d_1 = tf.compat.v1.layers.conv2d(inputImage, \n",
        "                               filters=4, \n",
        "                               kernel_size=[3,3],\n",
        "                               strides=[1,1], \n",
        "                               padding='SAME', \n",
        "                               activation=\"tanh\",\n",
        "                               kernel_regularizer = regularizer,\n",
        "                               name=\"conv2d_1\")\n",
        "conv2d_1_dropout = tf.nn.dropout(conv2d_1, rate=d_out)\n",
        "\n",
        "conv2d_2 = tf.compat.v1.layers.conv2d(conv2d_1_dropout, \n",
        "                               filters=6, \n",
        "                               kernel_size=[3,3],\n",
        "                               strides=[1,1], \n",
        "                               padding='SAME', \n",
        "                               activation=\"tanh\",\n",
        "                               kernel_regularizer = regularizer,\n",
        "                               name=\"conv2d_2\")\n",
        "conv2d_2_dropout = tf.nn.dropout(conv2d_2, rate=d_out*2)\n",
        "\n",
        "conv2d_3 = tf.compat.v1.layers.conv2d(conv2d_2_dropout, \n",
        "                               filters=8, \n",
        "                               kernel_size=[3,3],\n",
        "                               strides=[1,1], \n",
        "                               padding='SAME', \n",
        "                               activation=\"tanh\",\n",
        "                               kernel_regularizer = regularizer,\n",
        "                               name=\"conv2d_3\")\n",
        "conv2d_3_dropout = tf.nn.dropout(conv2d_3, rate=d_out*2)\n",
        "\n",
        "\n",
        "\n",
        "flat_layer = tf.reshape(conv2d_3, shape=\n",
        "                        [-1, conv2d_3.shape[1]*conv2d_3.shape[2]*conv2d_3.shape[3]])\n",
        "fc1 = tf.compat.v1.layers.dense(flat_layer, 32, activation=tf.nn.relu, \n",
        "                                kernel_regularizer = regularizer,\n",
        "                                name=\"fc1\")\n",
        "fc1_dropout = tf.nn.dropout(fc1, rate=d_out*2)\n",
        "\n",
        "fc2 = tf.compat.v1.layers.dense(fc1_dropout, 16, activation=tf.nn.relu, \n",
        "                                kernel_regularizer = regularizer,\n",
        "                                name=\"fc2\")\n",
        "fc2_dropout = tf.nn.dropout(fc2, rate=d_out)\n",
        "\n",
        "\n",
        "logit = tf.compat.v1.layers.dense(fc2_dropout,num_classes , \n",
        "                                   kernel_regularizer = regularizer,\n",
        "                                   name=\"logit\")\n",
        "\n",
        "'''\n",
        "#Adding Regularization loss\n",
        "vars   = tf.compat.v1.trainable_variables()\n",
        "lossL2 = tf.add_n([tf.nn.l2_loss(v) for v in vars\n",
        "                    if 'bias' not in v.name ]) * 0.001\n",
        "\n",
        "softmax = tf.nn.softmax(logits = logit)\n",
        "\n",
        "xentropy = tf.nn.softmax_cross_entropy_with_logits(\n",
        "    labels=label, logits=logit)\n",
        "\n",
        "loss = tf.reduce_mean(tf.math.square(xentropy))\n",
        "\n",
        "losses = tf.math.add(loss,lossL2)\n",
        "\n",
        "total_loss = tf.identity(losses, name=\"totalLoss\")\n",
        "\n",
        "optimizer = tf.compat.v1.train.AdamOptimizer(learning_rate=l_rate)\n",
        "training_op = optimizer.minimize(total_loss)\n",
        "\n",
        "\n",
        "# Evaluate model (with test logits, for dropout to be disabled)\n",
        "correct_pred = tf.equal(tf.argmax(logit, 1), tf.argmax(label, 1))\n",
        "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
        "\n",
        "# Initialize the variables (i.e. assign their default value)\n",
        "init = tf.compat.v1.global_variables_initializer()\n",
        "'''\n",
        "\n",
        "\n",
        "\n",
        "sigmoidal_ouput = tf.math.sigmoid(logit)\n",
        "xentropy = tf.nn.sigmoid_cross_entropy_with_logits(label, tf.reshape(logit, shape=[-1]))\n",
        "\n",
        "#Adding Regularization loss\n",
        "vars   = tf.compat.v1.trainable_variables()\n",
        "r_loss = tf.add_n([tf.nn.l2_loss(v) for v in vars\n",
        "                    if 'bias' not in v.name ]) * 0.01\n",
        "\n",
        "loss = tf.reduce_mean(xentropy)\n",
        "losses = tf.math.add(loss,r_loss)\n",
        "\n",
        "total_loss = tf.identity(losses, name=\"totalLoss\")\n",
        "optimizer = tf.compat.v1.train.AdamOptimizer(l_rate)\n",
        "training_op = optimizer.minimize(total_loss)\n",
        "\n",
        "init = tf.compat.v1.global_variables_initializer()\n"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-15-330f2dabac52>:23: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.keras.layers.Conv2D` instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/layers/convolutional.py:424: Layer.apply (from tensorflow.python.keras.engine.base_layer_v1) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.__call__` method instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py:1666: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "WARNING:tensorflow:From <ipython-input-15-330f2dabac52>:52: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.Dense instead.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7rtkXYDrnGyX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def binaryConvertor(arr):\n",
        "    binaryArray = []\n",
        "    for (index,val) in enumerate(arr):\n",
        "        if(arr[index]>=0.5):\n",
        "            binaryArray.append(1)\n",
        "        else:\n",
        "            binaryArray.append(0)\n",
        "    return np.asarray(binaryArray)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CEd3JAHSm9q3",
        "colab_type": "code",
        "outputId": "4e241c57-f2af-4275-c055-46e61f5da91d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 167
        }
      },
      "source": [
        "print(logit,\"\\n\",\"\\n\",total_loss, \"\\n\", label, \"\\n\", d_out, \"\\n\",xentropy, \"\\n\",\"\\n\",\"\\n\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensor(\"logit/BiasAdd:0\", shape=(None, 1), dtype=float32) \n",
            " \n",
            " Tensor(\"totalLoss:0\", shape=(), dtype=float32) \n",
            " Tensor(\"label:0\", shape=(None,), dtype=float32) \n",
            " Tensor(\"dropOut:0\", dtype=float32) \n",
            " Tensor(\"logistic_loss:0\", shape=(None,), dtype=float32) \n",
            " \n",
            " \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p9eKje5-nRQF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_batchofImage(X, y, bsize):\n",
        "    for batch_i in range(0, 1 + (len(X) //bsize)):\n",
        "        start_i = batch_i * bsize\n",
        "        try:\n",
        "            X_data = X[start_i:start_i + bsize]    \n",
        "            y_data = y[start_i:start_i + bsize]      \n",
        "        except IndexError:\n",
        "            X_data = X[start_i:]\n",
        "            y_data = y[start_i:]\n",
        "        yield np.array(X_data), np.array(y_data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "98GtW-QDnYpB",
        "colab_type": "code",
        "outputId": "6480119d-9dce-40a4-9b27-6f415d1d03cc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "n_epochs = 50\n",
        "trainingLoss = []\n",
        "testloss = []\n",
        "\n",
        "with tf.compat.v1.Session() as sess:\n",
        "    init.run()\n",
        "    saver = tf.compat.v1.train.Saver()\n",
        "    for epoch in range(n_epochs):\n",
        "        i = 0\n",
        "        cost = 0 \n",
        "        for index,(data,labels) in enumerate(get_batchofImage(train_X,train_Y,45)):\n",
        "            #print(data.shape, labels.shape)\n",
        "            if(len(data) == 0):\n",
        "                continue\n",
        "            l, prediction,_ = sess.run(( total_loss,sigmoidal_ouput, training_op), feed_dict={inputImage: data, label: labels, \n",
        "                                             l_rate:learningRate,d_out:dropOut\n",
        "                                             })\n",
        "            cost = cost+l\n",
        "            \n",
        "        cost = cost/index\n",
        "        trainingLoss.append(np.round(cost,6))\n",
        "        print(\"training loss:........\",np.round(cost,6))\n",
        "        if(epoch%10==0):\n",
        "          print(\"loss:  \", np.round(cost,6))\n",
        "          binary = binaryConvertor(prediction)\n",
        "          print(\"\\n\\n\\nTraining: labels:\",np.column_stack((labels,  np.round(prediction,6), binary)))\n",
        "        oldArray = []\n",
        "        for index,(data,labels) in enumerate(get_batchofImage(test_X,test_Y,90)):\n",
        "\n",
        "            l, out = sess.run((total_loss, sigmoidal_ouput), feed_dict={inputImage: data, label: labels, \n",
        "                                              l_rate:learningRate, d_out:0.0\n",
        "                                              })\n",
        "            pred = binaryConvertor(out)\n",
        "            testloss.append(np.round(l,6))\n",
        "            #oldArray = np.column_stack((oldArray, out))\n",
        "            print(\"test loss:*************************\",np.round(l,6))\n",
        "            #print(\"\\n\\n\\Testing:\",np.column_stack((labels, np.round(out,6), pred)))\n",
        "            break\n",
        "            # print(val.shape)\n",
        "           \n",
        "        #acc_train = accuracy.eval(feed_dict={X: X_bach, y: y_batch})\n",
        "        #acc_test = accuracy.eval(feed_dict={X: mnist.test.images, y: mnist.test.labels})\n",
        "        if(epoch%20==0):\n",
        "          print(\"\\n\\n\\Testing:\",np.column_stack((labels, np.round(out,6), pred)))\n",
        "            \n",
        "          #print( \"testloss:\", testloss, sess, saver)\n",
        "\n",
        "    try:\n",
        "      save_path = saver.save(sess, \"./throat/trained\")\n",
        "      print(\"saved\")\n",
        "    except Exception as e:\n",
        "      print(e)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "training loss:........ 3.615222\n",
            "loss:   3.615222\n",
            "\n",
            "\n",
            "\n",
            "Training: labels: [[1.         0.49886    0.        ]\n",
            " [1.         0.49886    0.        ]\n",
            " [1.         0.498606   0.        ]\n",
            " [1.         0.76921701 1.        ]\n",
            " [0.         0.498606   0.        ]\n",
            " [1.         0.79854703 1.        ]\n",
            " [1.         0.49886    0.        ]\n",
            " [1.         0.49975201 0.        ]\n",
            " [1.         0.49886    0.        ]\n",
            " [0.         0.49910399 0.        ]\n",
            " [0.         0.499762   0.        ]\n",
            " [0.         0.49905699 0.        ]\n",
            " [1.         0.49877101 0.        ]\n",
            " [0.         0.49910399 0.        ]\n",
            " [1.         0.61546999 1.        ]\n",
            " [1.         0.49886    0.        ]\n",
            " [0.         0.49886    0.        ]\n",
            " [1.         0.49886    0.        ]\n",
            " [0.         0.62589902 1.        ]\n",
            " [0.         0.49514899 0.        ]\n",
            " [1.         0.49886    0.        ]\n",
            " [0.         0.65490299 1.        ]\n",
            " [1.         0.49886    0.        ]\n",
            " [0.         0.49886    0.        ]\n",
            " [1.         0.49886    0.        ]\n",
            " [0.         0.49886    0.        ]\n",
            " [1.         0.87542802 1.        ]\n",
            " [1.         0.49886    0.        ]\n",
            " [0.         0.508349   1.        ]\n",
            " [0.         0.49886    0.        ]\n",
            " [1.         0.49886    0.        ]\n",
            " [1.         0.49880299 0.        ]\n",
            " [1.         0.49995899 0.        ]\n",
            " [1.         0.49886    0.        ]\n",
            " [0.         0.49886    0.        ]]\n",
            "test loss:************************* 1.937276\n",
            "\n",
            "\n",
            "\\Testing: [[1.         0.49907801 0.        ]\n",
            " [1.         0.49907801 0.        ]\n",
            " [1.         0.49907801 0.        ]\n",
            " [1.         0.49907801 0.        ]\n",
            " [1.         0.63259602 1.        ]\n",
            " [0.         0.49907801 0.        ]\n",
            " [1.         0.612809   1.        ]\n",
            " [1.         0.49907801 0.        ]\n",
            " [0.         0.49907801 0.        ]\n",
            " [1.         0.49907801 0.        ]\n",
            " [1.         0.49907801 0.        ]\n",
            " [0.         0.49907801 0.        ]\n",
            " [1.         0.49907801 0.        ]\n",
            " [1.         0.49907801 0.        ]\n",
            " [0.         0.49907801 0.        ]\n",
            " [1.         0.49907801 0.        ]\n",
            " [1.         0.49907801 0.        ]\n",
            " [0.         0.49907801 0.        ]\n",
            " [1.         0.49907801 0.        ]\n",
            " [0.         0.49907801 0.        ]\n",
            " [0.         0.49907801 0.        ]\n",
            " [0.         0.49907801 0.        ]\n",
            " [1.         0.51677001 1.        ]\n",
            " [1.         0.49907801 0.        ]\n",
            " [1.         0.49907801 0.        ]\n",
            " [0.         0.49907801 0.        ]\n",
            " [0.         0.49907801 0.        ]\n",
            " [0.         0.49907801 0.        ]\n",
            " [0.         0.49907801 0.        ]\n",
            " [0.         0.49907801 0.        ]]\n",
            "training loss:........ 1.767968\n",
            "test loss:************************* 1.546626\n",
            "training loss:........ 1.428319\n",
            "test loss:************************* 1.317959\n",
            "training loss:........ 1.205171\n",
            "test loss:************************* 1.111415\n",
            "training loss:........ 1.102116\n",
            "test loss:************************* 1.087348\n",
            "training loss:........ 1.156014\n",
            "test loss:************************* 1.166886\n",
            "training loss:........ 1.083148\n",
            "test loss:************************* 1.091682\n",
            "training loss:........ 1.233314\n",
            "test loss:************************* 1.390886\n",
            "training loss:........ 1.311615\n",
            "test loss:************************* 1.44353\n",
            "training loss:........ 1.429372\n",
            "test loss:************************* 1.346862\n",
            "training loss:........ 1.329778\n",
            "loss:   1.329778\n",
            "\n",
            "\n",
            "\n",
            "Training: labels: [[1.         0.87856698 1.        ]\n",
            " [1.         0.413551   0.        ]\n",
            " [1.         0.51086998 1.        ]\n",
            " [1.         0.98559499 1.        ]\n",
            " [0.         0.64049703 1.        ]\n",
            " [1.         0.98933399 1.        ]\n",
            " [1.         0.76738602 1.        ]\n",
            " [1.         0.63424599 1.        ]\n",
            " [1.         0.48219901 0.        ]\n",
            " [0.         0.522919   1.        ]\n",
            " [0.         0.77332801 1.        ]\n",
            " [0.         0.50009102 1.        ]\n",
            " [1.         0.99245399 1.        ]\n",
            " [0.         0.194177   0.        ]\n",
            " [1.         0.25710699 0.        ]\n",
            " [1.         0.91198301 1.        ]\n",
            " [0.         0.44619301 0.        ]\n",
            " [1.         0.203908   0.        ]\n",
            " [0.         0.75098503 1.        ]\n",
            " [0.         0.33464    0.        ]\n",
            " [1.         0.834144   1.        ]\n",
            " [0.         0.59161001 1.        ]\n",
            " [1.         0.57435    1.        ]\n",
            " [0.         0.48921999 0.        ]\n",
            " [1.         0.52220798 1.        ]\n",
            " [0.         0.38981101 0.        ]\n",
            " [1.         0.99129999 1.        ]\n",
            " [1.         0.065841   0.        ]\n",
            " [0.         0.241055   0.        ]\n",
            " [0.         0.039116   0.        ]\n",
            " [1.         0.75097603 1.        ]\n",
            " [1.         0.62366003 1.        ]\n",
            " [1.         0.405826   0.        ]\n",
            " [1.         0.99615699 1.        ]\n",
            " [0.         0.38174999 0.        ]]\n",
            "test loss:************************* 1.564871\n",
            "training loss:........ 1.453407\n",
            "test loss:************************* 1.667445\n",
            "training loss:........ 1.430823\n",
            "test loss:************************* 1.552436\n",
            "training loss:........ 1.332082\n",
            "test loss:************************* 1.518153\n",
            "training loss:........ 1.231303\n",
            "test loss:************************* 1.590464\n",
            "training loss:........ 1.233155\n",
            "test loss:************************* 1.795853\n",
            "training loss:........ 1.095497\n",
            "test loss:************************* 1.490975\n",
            "training loss:........ 1.051551\n",
            "test loss:************************* 1.248735\n",
            "training loss:........ 0.949779\n",
            "test loss:************************* 1.4112\n",
            "training loss:........ 1.066375\n",
            "test loss:************************* 1.503758\n",
            "training loss:........ 0.92795\n",
            "loss:   0.92795\n",
            "\n",
            "\n",
            "\n",
            "Training: labels: [[1.00000000e+00 8.30973029e-01 1.00000000e+00]\n",
            " [1.00000000e+00 6.20199978e-01 1.00000000e+00]\n",
            " [1.00000000e+00 8.89985025e-01 1.00000000e+00]\n",
            " [1.00000000e+00 9.85678017e-01 1.00000000e+00]\n",
            " [0.00000000e+00 5.36433995e-01 1.00000000e+00]\n",
            " [1.00000000e+00 9.38326001e-01 1.00000000e+00]\n",
            " [1.00000000e+00 8.94788980e-01 1.00000000e+00]\n",
            " [1.00000000e+00 9.64634001e-01 1.00000000e+00]\n",
            " [1.00000000e+00 8.45380008e-01 1.00000000e+00]\n",
            " [0.00000000e+00 7.84450024e-02 0.00000000e+00]\n",
            " [0.00000000e+00 3.55075002e-01 0.00000000e+00]\n",
            " [0.00000000e+00 2.24671006e-01 0.00000000e+00]\n",
            " [1.00000000e+00 9.24427986e-01 1.00000000e+00]\n",
            " [0.00000000e+00 3.80500010e-03 0.00000000e+00]\n",
            " [1.00000000e+00 6.62308991e-01 1.00000000e+00]\n",
            " [1.00000000e+00 9.85171020e-01 1.00000000e+00]\n",
            " [0.00000000e+00 4.84735012e-01 0.00000000e+00]\n",
            " [1.00000000e+00 9.23035026e-01 1.00000000e+00]\n",
            " [0.00000000e+00 2.97250986e-01 0.00000000e+00]\n",
            " [0.00000000e+00 2.15690002e-01 0.00000000e+00]\n",
            " [1.00000000e+00 9.99661982e-01 1.00000000e+00]\n",
            " [0.00000000e+00 5.58767974e-01 1.00000000e+00]\n",
            " [1.00000000e+00 9.93636012e-01 1.00000000e+00]\n",
            " [0.00000000e+00 4.30790000e-02 0.00000000e+00]\n",
            " [1.00000000e+00 8.84447992e-01 1.00000000e+00]\n",
            " [0.00000000e+00 1.63742006e-01 0.00000000e+00]\n",
            " [1.00000000e+00 9.67552006e-01 1.00000000e+00]\n",
            " [1.00000000e+00 9.97300982e-01 1.00000000e+00]\n",
            " [0.00000000e+00 1.29879996e-01 0.00000000e+00]\n",
            " [0.00000000e+00 1.63999997e-04 0.00000000e+00]\n",
            " [1.00000000e+00 9.88680005e-01 1.00000000e+00]\n",
            " [1.00000000e+00 8.99739027e-01 1.00000000e+00]\n",
            " [1.00000000e+00 6.97606027e-01 1.00000000e+00]\n",
            " [1.00000000e+00 9.97577012e-01 1.00000000e+00]\n",
            " [0.00000000e+00 1.27937004e-01 0.00000000e+00]]\n",
            "test loss:************************* 1.431195\n",
            "\n",
            "\n",
            "\\Testing: [[1.         0.71050102 1.        ]\n",
            " [1.         0.214191   0.        ]\n",
            " [1.         0.97719401 1.        ]\n",
            " [1.         0.935009   1.        ]\n",
            " [1.         0.27443901 0.        ]\n",
            " [0.         0.345963   0.        ]\n",
            " [1.         0.90506202 1.        ]\n",
            " [1.         0.098107   0.        ]\n",
            " [0.         0.933285   1.        ]\n",
            " [1.         0.79838997 1.        ]\n",
            " [1.         0.63049698 1.        ]\n",
            " [0.         0.95444298 1.        ]\n",
            " [1.         0.79580098 1.        ]\n",
            " [1.         0.101241   0.        ]\n",
            " [0.         0.233731   0.        ]\n",
            " [1.         0.52777302 1.        ]\n",
            " [1.         0.96396899 1.        ]\n",
            " [0.         0.32248601 0.        ]\n",
            " [1.         0.82550502 1.        ]\n",
            " [0.         0.004305   0.        ]\n",
            " [0.         0.90152103 1.        ]\n",
            " [0.         0.36821401 0.        ]\n",
            " [1.         0.94351798 1.        ]\n",
            " [1.         0.946962   1.        ]\n",
            " [1.         0.98724198 1.        ]\n",
            " [0.         0.022284   0.        ]\n",
            " [0.         0.089951   0.        ]\n",
            " [0.         0.91787302 1.        ]\n",
            " [0.         0.71100003 1.        ]\n",
            " [0.         0.87154698 1.        ]]\n",
            "training loss:........ 0.843528\n",
            "test loss:************************* 1.604629\n",
            "training loss:........ 0.905854\n",
            "test loss:************************* 1.442687\n",
            "training loss:........ 0.814041\n",
            "test loss:************************* 1.8803\n",
            "training loss:........ 0.902629\n",
            "test loss:************************* 1.668727\n",
            "training loss:........ 0.885062\n",
            "test loss:************************* 1.409182\n",
            "training loss:........ 0.855519\n",
            "test loss:************************* 1.456189\n",
            "training loss:........ 0.851543\n",
            "test loss:************************* 1.346028\n",
            "training loss:........ 0.872746\n",
            "test loss:************************* 1.30921\n",
            "training loss:........ 0.860742\n",
            "test loss:************************* 1.393412\n",
            "training loss:........ 0.870929\n",
            "loss:   0.870929\n",
            "\n",
            "\n",
            "\n",
            "Training: labels: [[1.00000000e+00 9.87473011e-01 1.00000000e+00]\n",
            " [1.00000000e+00 5.68858981e-01 1.00000000e+00]\n",
            " [1.00000000e+00 9.82396007e-01 1.00000000e+00]\n",
            " [1.00000000e+00 9.97686028e-01 1.00000000e+00]\n",
            " [0.00000000e+00 1.73419993e-02 0.00000000e+00]\n",
            " [1.00000000e+00 9.79539990e-01 1.00000000e+00]\n",
            " [1.00000000e+00 9.03868020e-01 1.00000000e+00]\n",
            " [1.00000000e+00 3.99468005e-01 0.00000000e+00]\n",
            " [1.00000000e+00 2.89983988e-01 0.00000000e+00]\n",
            " [0.00000000e+00 2.72942007e-01 0.00000000e+00]\n",
            " [0.00000000e+00 1.25272006e-01 0.00000000e+00]\n",
            " [0.00000000e+00 3.15079987e-02 0.00000000e+00]\n",
            " [1.00000000e+00 9.96896982e-01 1.00000000e+00]\n",
            " [0.00000000e+00 6.00000021e-06 0.00000000e+00]\n",
            " [1.00000000e+00 9.47290003e-01 1.00000000e+00]\n",
            " [1.00000000e+00 9.98058021e-01 1.00000000e+00]\n",
            " [0.00000000e+00 1.05229998e-02 0.00000000e+00]\n",
            " [1.00000000e+00 3.97839010e-01 0.00000000e+00]\n",
            " [0.00000000e+00 6.01659000e-01 1.00000000e+00]\n",
            " [0.00000000e+00 2.09775999e-01 0.00000000e+00]\n",
            " [1.00000000e+00 8.88540030e-01 1.00000000e+00]\n",
            " [0.00000000e+00 3.19635004e-01 0.00000000e+00]\n",
            " [1.00000000e+00 9.71747994e-01 1.00000000e+00]\n",
            " [0.00000000e+00 1.07000000e-04 0.00000000e+00]\n",
            " [1.00000000e+00 1.98056996e-01 0.00000000e+00]\n",
            " [0.00000000e+00 1.57896996e-01 0.00000000e+00]\n",
            " [1.00000000e+00 5.70447981e-01 1.00000000e+00]\n",
            " [1.00000000e+00 9.95813012e-01 1.00000000e+00]\n",
            " [0.00000000e+00 5.82830012e-02 0.00000000e+00]\n",
            " [0.00000000e+00 1.36000002e-04 0.00000000e+00]\n",
            " [1.00000000e+00 9.99392986e-01 1.00000000e+00]\n",
            " [1.00000000e+00 2.98375994e-01 0.00000000e+00]\n",
            " [1.00000000e+00 6.75629973e-01 1.00000000e+00]\n",
            " [1.00000000e+00 9.90194023e-01 1.00000000e+00]\n",
            " [0.00000000e+00 2.07119994e-02 0.00000000e+00]]\n",
            "test loss:************************* 1.199134\n",
            "training loss:........ 0.890545\n",
            "test loss:************************* 1.449735\n",
            "training loss:........ 0.798233\n",
            "test loss:************************* 1.294166\n",
            "training loss:........ 0.814927\n",
            "test loss:************************* 1.25584\n",
            "training loss:........ 0.890107\n",
            "test loss:************************* 1.378489\n",
            "training loss:........ 0.877278\n",
            "test loss:************************* 1.288065\n",
            "training loss:........ 0.808989\n",
            "test loss:************************* 1.279064\n",
            "training loss:........ 0.895524\n",
            "test loss:************************* 1.353164\n",
            "training loss:........ 0.877043\n",
            "test loss:************************* 1.470387\n",
            "training loss:........ 0.778375\n",
            "test loss:************************* 1.413667\n",
            "training loss:........ 0.836376\n",
            "loss:   0.836376\n",
            "\n",
            "\n",
            "\n",
            "Training: labels: [[1.00000000e+00 3.85697991e-01 0.00000000e+00]\n",
            " [1.00000000e+00 9.87134993e-01 1.00000000e+00]\n",
            " [1.00000000e+00 9.67117012e-01 1.00000000e+00]\n",
            " [1.00000000e+00 9.19960022e-01 1.00000000e+00]\n",
            " [0.00000000e+00 4.59479988e-02 0.00000000e+00]\n",
            " [1.00000000e+00 8.95384014e-01 1.00000000e+00]\n",
            " [1.00000000e+00 7.62781024e-01 1.00000000e+00]\n",
            " [1.00000000e+00 4.00332987e-01 0.00000000e+00]\n",
            " [1.00000000e+00 9.71342981e-01 1.00000000e+00]\n",
            " [0.00000000e+00 6.53000025e-04 0.00000000e+00]\n",
            " [0.00000000e+00 3.69750001e-02 0.00000000e+00]\n",
            " [0.00000000e+00 9.90999979e-04 0.00000000e+00]\n",
            " [1.00000000e+00 9.98506010e-01 1.00000000e+00]\n",
            " [0.00000000e+00 6.31230026e-02 0.00000000e+00]\n",
            " [1.00000000e+00 3.51499999e-03 0.00000000e+00]\n",
            " [1.00000000e+00 9.97485995e-01 1.00000000e+00]\n",
            " [0.00000000e+00 7.37799983e-03 0.00000000e+00]\n",
            " [1.00000000e+00 9.12856996e-01 1.00000000e+00]\n",
            " [0.00000000e+00 1.43029997e-02 0.00000000e+00]\n",
            " [0.00000000e+00 9.11459997e-02 0.00000000e+00]\n",
            " [1.00000000e+00 9.99359012e-01 1.00000000e+00]\n",
            " [0.00000000e+00 3.75768006e-01 0.00000000e+00]\n",
            " [1.00000000e+00 9.77141976e-01 1.00000000e+00]\n",
            " [0.00000000e+00 9.47399996e-03 0.00000000e+00]\n",
            " [1.00000000e+00 8.01643014e-01 1.00000000e+00]\n",
            " [0.00000000e+00 4.02455986e-01 0.00000000e+00]\n",
            " [1.00000000e+00 4.66599986e-02 0.00000000e+00]\n",
            " [1.00000000e+00 9.46662009e-01 1.00000000e+00]\n",
            " [0.00000000e+00 3.94441009e-01 0.00000000e+00]\n",
            " [0.00000000e+00 3.56947988e-01 0.00000000e+00]\n",
            " [1.00000000e+00 9.95791018e-01 1.00000000e+00]\n",
            " [1.00000000e+00 9.79667008e-01 1.00000000e+00]\n",
            " [1.00000000e+00 9.99836028e-01 1.00000000e+00]\n",
            " [1.00000000e+00 9.39131975e-01 1.00000000e+00]\n",
            " [0.00000000e+00 1.90762997e-01 0.00000000e+00]]\n",
            "test loss:************************* 1.368958\n",
            "\n",
            "\n",
            "\\Testing: [[1.         0.43534401 0.        ]\n",
            " [1.         0.407078   0.        ]\n",
            " [1.         0.98177302 1.        ]\n",
            " [1.         0.98060203 1.        ]\n",
            " [1.         0.85727799 1.        ]\n",
            " [0.         0.078272   0.        ]\n",
            " [1.         0.76218897 1.        ]\n",
            " [1.         0.098872   0.        ]\n",
            " [0.         0.27115801 0.        ]\n",
            " [1.         0.759435   1.        ]\n",
            " [1.         0.041328   0.        ]\n",
            " [0.         0.92138398 1.        ]\n",
            " [1.         0.579597   1.        ]\n",
            " [1.         0.87026697 1.        ]\n",
            " [0.         0.22979499 0.        ]\n",
            " [1.         0.74333203 1.        ]\n",
            " [1.         0.98832202 1.        ]\n",
            " [0.         0.312168   0.        ]\n",
            " [1.         0.94020402 1.        ]\n",
            " [0.         0.060012   0.        ]\n",
            " [0.         0.98312402 1.        ]\n",
            " [0.         0.021674   0.        ]\n",
            " [1.         0.99120897 1.        ]\n",
            " [1.         0.79018402 1.        ]\n",
            " [1.         0.98247302 1.        ]\n",
            " [0.         0.046128   0.        ]\n",
            " [0.         0.95865601 1.        ]\n",
            " [0.         0.16211399 0.        ]\n",
            " [0.         0.317155   0.        ]\n",
            " [0.         0.83545703 1.        ]]\n",
            "training loss:........ 0.889523\n",
            "test loss:************************* 1.496558\n",
            "training loss:........ 0.896758\n",
            "test loss:************************* 1.804298\n",
            "training loss:........ 0.984805\n",
            "test loss:************************* 1.285507\n",
            "training loss:........ 0.894649\n",
            "test loss:************************* 1.375427\n",
            "training loss:........ 0.804713\n",
            "test loss:************************* 1.150983\n",
            "training loss:........ 0.763276\n",
            "test loss:************************* 1.424272\n",
            "training loss:........ 0.836612\n",
            "test loss:************************* 1.291134\n",
            "training loss:........ 0.780143\n",
            "test loss:************************* 1.603166\n",
            "training loss:........ 0.848133\n",
            "test loss:************************* 1.585219\n",
            "saved\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YCfJZOPaMzB2",
        "colab_type": "code",
        "outputId": "a52a728b-c63a-4ed3-a1fd-1fe2c20363ac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "source": [
        "from matplotlib import pyplot as plt\n",
        "plt.plot(trainingLoss[5:])\n",
        "#plt.plot(testloss)\n",
        "plt.title('Loss')\n",
        "plt.ylabel('Trainging and test') \n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kVhw0isrM7rG",
        "colab_type": "code",
        "outputId": "4f1e78f5-d329-46ce-8389-d4555935976b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "source": [
        "from matplotlib import pyplot as plt\n",
        "#plt.plot(trainingLoss)\n",
        "plt.plot(testloss[5:])\n",
        "plt.title('Loss')\n",
        "plt.ylabel('Trainging and test') \n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1dyO3LyicfZh",
        "colab_type": "code",
        "outputId": "651b4e73-d020-4088-eea0-e08d07d43cb4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 100
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import recall_score\n",
        "# Later, launch the model, use the saver to restore variables from disk, and\n",
        "# do some work with the model.\n",
        "losses =[]\n",
        "tf.compat.v1.disable_eager_execution()\n",
        "tf.compat.v1.reset_default_graph()\n",
        "   \n",
        "with tf.compat.v1.Session() as sess:\n",
        "  # Restore variables from disk.\n",
        "  saver = tf.compat.v1.train.import_meta_graph('{0}.meta'.format( \"./throat/trained\"))       \n",
        "  saver.restore(sess, \"./throat/trained\")\n",
        "  print(\"*******************************Model restored.\")\n",
        "  inputImage = tf.compat.v1.get_default_graph().get_tensor_by_name('X:0')\n",
        "  label =       tf.compat.v1.get_default_graph().get_tensor_by_name('label:0')\n",
        "  sigmoidal_ouput =       tf.compat.v1.get_default_graph().get_tensor_by_name('Sigmoid:0')\n",
        "  \n",
        "  totalLoss =  tf.compat.v1.get_default_graph().get_tensor_by_name('totalLoss:0')\n",
        "  d_out =  tf.compat.v1.get_default_graph().get_tensor_by_name(\"dropOut:0\")\n",
        "  #pred =  tf.compat.v1.get_default_graph().get_tensor_by_name(\"Equal:0\")\n",
        "  #acc =  tf.compat.v1.get_default_graph().get_tensor_by_name(\"Mean_1:0\")\n",
        "  logit =  tf.compat.v1.get_default_graph().get_tensor_by_name('logit/BiasAdd:0')\n",
        " \n",
        "\n",
        "  \n",
        "\n",
        "  for index,(data,labels) in enumerate(get_batchofImage(test_X,test_Y,200)):\n",
        "\n",
        "          l, out = sess.run((totalLoss, sigmoidal_ouput), feed_dict={inputImage: data, label: labels, d_out:0.0\n",
        "                                            })\n",
        "          pred = binaryConvertor(out)\n",
        "          #losses.append(np.round(l,6))\n",
        "          #oldArray = np.column_stack((oldArray, out))\n",
        "          #print(\"\\n\\n\\Testing:\",l, \"\\n\",np.column_stack((labels, np.round(out,6), pred)))\n",
        "          print(confusion_matrix(labels,pred))\n",
        "          print(recall_score(labels,pred))\n",
        "          break"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Restoring parameters from ./throat/trained\n",
            "*******************************Model restored.\n",
            "[[11  2]\n",
            " [ 8  9]]\n",
            "0.5294117647058824\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zEPCYDV_9PAK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "szwjjIHH9PD9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FgHNnoGU9POR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oyC6lvJt9PUj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I5_ZlLj29O-b",
        "colab_type": "code",
        "outputId": "a237f9fb-9fae-4ac2-d668-6191b66382a3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        }
      },
      "source": [
        "pip install tensornets\n"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensornets\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/22/2c9402bbf142b94dc39d8a3c9884690ae87706a8bc1453d6cf0630525173/tensornets-0.4.6.tar.gz (651kB)\n",
            "\r\u001b[K     |▌                               | 10kB 23.4MB/s eta 0:00:01\r\u001b[K     |█                               | 20kB 1.7MB/s eta 0:00:01\r\u001b[K     |█▌                              | 30kB 2.3MB/s eta 0:00:01\r\u001b[K     |██                              | 40kB 2.6MB/s eta 0:00:01\r\u001b[K     |██▌                             | 51kB 2.0MB/s eta 0:00:01\r\u001b[K     |███                             | 61kB 2.3MB/s eta 0:00:01\r\u001b[K     |███▌                            | 71kB 2.6MB/s eta 0:00:01\r\u001b[K     |████                            | 81kB 2.8MB/s eta 0:00:01\r\u001b[K     |████▌                           | 92kB 2.9MB/s eta 0:00:01\r\u001b[K     |█████                           | 102kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 112kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████                          | 122kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 133kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████                         | 143kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████▌                        | 153kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████                        | 163kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 174kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████                       | 184kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 194kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████                      | 204kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 215kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████                     | 225kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 235kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████                    | 245kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 256kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 266kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 276kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 286kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 296kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 307kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 317kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████                | 327kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 337kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 348kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 358kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 368kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 378kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 389kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 399kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 409kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 419kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 430kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 440kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████▏         | 450kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 460kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 471kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 481kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 491kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████▋       | 501kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 512kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 522kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 532kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 542kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▏    | 552kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▊    | 563kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 573kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▊   | 583kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 593kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 604kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▏ | 614kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 624kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 634kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 645kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 655kB 2.8MB/s \n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[33m  WARNING: Missing build requirements in pyproject.toml for tensornets from https://files.pythonhosted.org/packages/71/22/2c9402bbf142b94dc39d8a3c9884690ae87706a8bc1453d6cf0630525173/tensornets-0.4.6.tar.gz#sha256=e1095082b45a06168d56450d8c8fa49780d8aef8d4d1fcc64efceadb743f9ceb.\u001b[0m\n",
            "\u001b[33m  WARNING: The project does not specify a build backend, and pip cannot fall back to setuptools without 'wheel'.\u001b[0m\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: tensornets\n",
            "  Building wheel for tensornets (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for tensornets: filename=tensornets-0.4.6-cp36-cp36m-linux_x86_64.whl size=1222191 sha256=bbd4c92cf1272aa2fa49db5a69c134b71fd6a54f7f161275b73d6f73e4a408cd\n",
            "  Stored in directory: /root/.cache/pip/wheels/89/18/ea/82c6d494fb3ae5e080cd34bd3cff9f92ddbf3292fcfa9e3ce5\n",
            "Successfully built tensornets\n",
            "Installing collected packages: tensornets\n",
            "Successfully installed tensornets-0.4.6\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kxMKxMMy9O8T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import tensornets as nets"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dT2t8Tqw9O41",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learningRate = 0.005\n",
        "dropOut = 0.10"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gl4_DSwY98GL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tf.compat.v1.disable_eager_execution()\n",
        "tf.compat.v1.reset_default_graph()\n",
        "\n",
        "x = tf.compat.v1.placeholder(tf.float32, shape=(None, 224, 224, 3), name='input_x')\n",
        "y = tf.compat.v1.placeholder(tf.float32, shape=(None), name='output_y')\n",
        "l_rate = tf.compat.v1.placeholder(tf.float32, name=\"rate\")\n",
        "\n",
        "regularizer = tf.keras.regularizers.l2()\n",
        "vgg19 = nets.VGG19(x, is_training=True, classes=20)\n",
        "model = tf.identity(vgg19, name='logits')\n",
        "lastFC = tf.compat.v1.get_default_graph().get_tensor_by_name('vgg19/drop7/dropout/Mul_1:0')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "fc1 = tf.compat.v1.layers.dense(lastFC, 64, \n",
        "                                   kernel_regularizer = regularizer,\n",
        "                                   activation = tf.nn.leaky_relu,\n",
        "                                   name=\"fc1\")\n",
        "\n",
        "logit = tf.compat.v1.layers.dense(fc1, 1, \n",
        "                                   kernel_regularizer = regularizer,\n",
        "                                   name=\"fc2\")\n",
        "\n",
        "sigmoidal_ouput = tf.math.sigmoid(logit, name = 'sig_output')\n",
        "xentropy = tf.nn.sigmoid_cross_entropy_with_logits(labels = y, logits = tf.reshape(logit, shape=[-1]))\n",
        "\n",
        "\n",
        "\n",
        "vars   = tf.compat.v1.trainable_variables()\n",
        "lossL2 = tf.add_n([tf.nn.l2_loss(v) for v in vars\n",
        "                    if 'bias' not in v.name ]) * 0.005\n",
        "\n",
        "loss = tf.reduce_mean(xentropy)\n",
        "total_loss = tf.math.add(loss,lossL2, name=\"sum\")\n",
        "\n",
        "losses = tf.identity(total_loss, \"accumulated_loss\")\n",
        "\n",
        "optimizer = tf.compat.v1.train.AdamOptimizer(l_rate)\n",
        "training_op = optimizer.minimize(losses)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6_wsdjMG-47S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_batch(arr, label, bsize):\n",
        "    for batch_i in range(0, 1 + (len(arr) //bsize)):\n",
        "        start_i = batch_i * bsize\n",
        "        try:\n",
        "            X = arr[start_i:start_i + bsize]  \n",
        "            y = label[start_i:start_i + bsize]  \n",
        "        except IndexError:\n",
        "            X = arr[start_i:]\n",
        "            y = label[start_i:]\n",
        "        #print(X.shape, y.shape)\n",
        "        yield X,y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1rSUiUST-7rj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def binaryConvertor(arr):\n",
        "    binaryArray = []\n",
        "    for (index,val) in enumerate(arr):\n",
        "        if(arr[index]>=0.5):\n",
        "            binaryArray.append(1)\n",
        "        else:\n",
        "            binaryArray.append(0)\n",
        "    return np.asarray(binaryArray)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pc--4trM--Vd",
        "colab_type": "code",
        "outputId": "3cf20173-b8b1-4775-d0cb-f0ef2be778d1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "epochs = 20\n",
        "trainingLoss = []\n",
        "testloss = []\n",
        "\n",
        "print('Training...')\n",
        "with tf.compat.v1.Session() as sess:    \n",
        "    # Initializing the variables\n",
        "    sess.run(tf.compat.v1.global_variables_initializer())\n",
        "\n",
        "\n",
        "    saver = tf.compat.v1.train.Saver()\n",
        "    #saver.restore(sess, tf.train.latest_checkpoint('./transferLearning/'))\n",
        "    \n",
        "    \n",
        "    \n",
        "    print('global_variables_initializer ... done ...')\n",
        "    sess.run(vgg19.pretrained())\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        i = 0\n",
        "        cost = 0 \n",
        "        for index,(data,labels) in enumerate(get_batch(train_X,train_Y,35)):\n",
        "            if(len(data) == 0):\n",
        "                continue\n",
        "            l, prediction,_ = sess.run((losses, sigmoidal_ouput, training_op), feed_dict={x: data,\n",
        "                                                                                          y: labels,\n",
        "                                                                                          l_rate:learningRate})\n",
        "            \n",
        "            cost = cost+l\n",
        "            \n",
        "        cost = cost/index\n",
        "        trainingLoss.append(np.round(cost,6))\n",
        "\n",
        "        print(\"Training loss:  \", np.round(cost,6))\n",
        "        binary = binaryConvertor(prediction)\n",
        "        print(\"\\n\\n\\nTraining: labels:\",np.column_stack((labels,  np.round(prediction,6), binary)))\n",
        "        oldArray = []\n",
        "        for index,(data,labels) in enumerate(get_batch(test_X,test_Y,90)):\n",
        "\n",
        "            l, out = sess.run((losses, sigmoidal_ouput), feed_dict={x: data, y: labels, \n",
        "                                              l_rate:learningRate})\n",
        "            pred = binaryConvertor(out)\n",
        "            testloss.append(np.round(l,6))\n",
        "            #oldArray = np.column_stack((oldArray, out))\n",
        "            print(\"\\n\\n\\Testing:\",np.column_stack((labels, np.round(out,6), pred)))\n",
        "            break\n",
        "            # print(val.shape)\n",
        "           \n",
        "    \n",
        "    \n",
        "    \n",
        "    \n",
        "    # Save Model\n",
        "    print(\"saving model\")\n",
        "    \n",
        "    save_path = saver.save(sess, './transferLearning/model')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training...\n",
            "global_variables_initializer ... done ...\n",
            "Downloading data from https://github.com/taehoonlee/deep-learning-models/releases/download/vgg/vgg19_weights_tf_dim_ordering_tf_kernels.h5\n",
            "574717952/574710816 [==============================] - 6s 0us/step\n",
            "Training loss:   80048145742.72206\n",
            "\n",
            "\n",
            "\n",
            "Training: labels: [[0. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 0. 0.]]\n",
            "\n",
            "\n",
            "\\Testing: [[1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [0. 0. 0.]]\n",
            "Training loss:   3149.2094\n",
            "\n",
            "\n",
            "\n",
            "Training: labels: [[0.         1.         1.        ]\n",
            " [1.         1.         1.        ]\n",
            " [1.         0.99899501 1.        ]\n",
            " [0.         1.         1.        ]\n",
            " [0.         0.         0.        ]\n",
            " [1.         1.         1.        ]\n",
            " [1.         1.         1.        ]\n",
            " [0.         1.         1.        ]\n",
            " [1.         1.         1.        ]\n",
            " [1.         1.         1.        ]\n",
            " [0.         1.         1.        ]\n",
            " [0.         1.         1.        ]\n",
            " [0.         0.         0.        ]\n",
            " [0.         1.         1.        ]\n",
            " [1.         0.         0.        ]\n",
            " [1.         0.         0.        ]\n",
            " [0.         0.016904   0.        ]\n",
            " [0.         1.         1.        ]\n",
            " [1.         1.         1.        ]\n",
            " [0.         1.         1.        ]]\n",
            "\n",
            "\n",
            "\\Testing: [[1.00000000e+00 1.00000000e+00 1.00000000e+00]\n",
            " [1.00000000e+00 1.00000000e+00 1.00000000e+00]\n",
            " [1.00000000e+00 9.99894023e-01 1.00000000e+00]\n",
            " [1.00000000e+00 1.00000000e+00 1.00000000e+00]\n",
            " [1.00000000e+00 1.00000000e+00 1.00000000e+00]\n",
            " [0.00000000e+00 1.00000000e+00 1.00000000e+00]\n",
            " [1.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
            " [1.00000000e+00 9.99740005e-01 1.00000000e+00]\n",
            " [0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
            " [1.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
            " [1.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
            " [0.00000000e+00 1.00000000e+00 1.00000000e+00]\n",
            " [1.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
            " [1.00000000e+00 1.00000000e+00 1.00000000e+00]\n",
            " [0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
            " [1.00000000e+00 4.80000017e-05 0.00000000e+00]\n",
            " [1.00000000e+00 1.60000000e-05 0.00000000e+00]\n",
            " [0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
            " [1.00000000e+00 1.00000000e+00 1.00000000e+00]\n",
            " [0.00000000e+00 1.00000000e+00 1.00000000e+00]\n",
            " [0.00000000e+00 1.00000000e+00 1.00000000e+00]\n",
            " [0.00000000e+00 8.38671982e-01 1.00000000e+00]\n",
            " [1.00000000e+00 1.00000000e+00 1.00000000e+00]\n",
            " [1.00000000e+00 1.00000000e+00 1.00000000e+00]\n",
            " [1.00000000e+00 8.24898005e-01 1.00000000e+00]\n",
            " [0.00000000e+00 9.99541998e-01 1.00000000e+00]\n",
            " [0.00000000e+00 1.00000000e+00 1.00000000e+00]\n",
            " [0.00000000e+00 1.00000000e+00 1.00000000e+00]\n",
            " [0.00000000e+00 2.90000007e-05 0.00000000e+00]\n",
            " [0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
            " [0.00000000e+00 1.00000000e+00 1.00000000e+00]\n",
            " [1.00000000e+00 1.00000000e+00 1.00000000e+00]\n",
            " [1.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
            " [1.00000000e+00 1.00000000e+00 1.00000000e+00]\n",
            " [0.00000000e+00 1.00000000e+00 1.00000000e+00]\n",
            " [1.00000000e+00 1.00000000e+00 1.00000000e+00]\n",
            " [0.00000000e+00 1.00000000e+00 1.00000000e+00]\n",
            " [1.00000000e+00 1.15966998e-01 0.00000000e+00]\n",
            " [0.00000000e+00 1.00000000e+00 1.00000000e+00]\n",
            " [0.00000000e+00 9.99979019e-01 1.00000000e+00]]\n",
            "Training loss:   1851.418483\n",
            "\n",
            "\n",
            "\n",
            "Training: labels: [[0. 1. 1.]\n",
            " [1. 1. 1.]\n",
            " [1. 1. 1.]\n",
            " [0. 0. 0.]\n",
            " [0. 1. 1.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 1. 1.]\n",
            " [0. 1. 1.]\n",
            " [0. 1. 1.]\n",
            " [0. 1. 1.]\n",
            " [0. 0. 0.]\n",
            " [1. 1. 1.]\n",
            " [1. 1. 1.]\n",
            " [0. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 0. 0.]]\n",
            "\n",
            "\n",
            "\\Testing: [[1. 0. 0.]\n",
            " [1. 1. 1.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 1. 1.]\n",
            " [1. 1. 1.]\n",
            " [1. 0. 0.]\n",
            " [0. 1. 1.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 1. 1.]\n",
            " [1. 1. 1.]\n",
            " [1. 0. 0.]\n",
            " [0. 1. 1.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 1. 1.]\n",
            " [0. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [1. 1. 1.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 1. 1.]\n",
            " [0. 1. 1.]\n",
            " [0. 1. 1.]\n",
            " [0. 0. 0.]\n",
            " [0. 1. 1.]\n",
            " [0. 0. 0.]\n",
            " [1. 1. 1.]\n",
            " [1. 1. 1.]\n",
            " [1. 0. 0.]\n",
            " [0. 1. 1.]\n",
            " [1. 0. 0.]\n",
            " [0. 1. 1.]\n",
            " [1. 0. 0.]\n",
            " [0. 1. 1.]\n",
            " [0. 0. 0.]]\n",
            "Training loss:   320.448139\n",
            "\n",
            "\n",
            "\n",
            "Training: labels: [[0.00000000e+00 9.41307008e-01 1.00000000e+00]\n",
            " [1.00000000e+00 8.45999981e-04 0.00000000e+00]\n",
            " [1.00000000e+00 1.33300005e-02 0.00000000e+00]\n",
            " [0.00000000e+00 9.39235985e-01 1.00000000e+00]\n",
            " [0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
            " [1.00000000e+00 9.95634019e-01 1.00000000e+00]\n",
            " [1.00000000e+00 8.66239965e-02 0.00000000e+00]\n",
            " [0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
            " [1.00000000e+00 7.51779020e-01 1.00000000e+00]\n",
            " [1.00000000e+00 3.55686009e-01 0.00000000e+00]\n",
            " [0.00000000e+00 8.93258989e-01 1.00000000e+00]\n",
            " [0.00000000e+00 6.05750009e-02 0.00000000e+00]\n",
            " [0.00000000e+00 8.78999999e-04 0.00000000e+00]\n",
            " [0.00000000e+00 1.26000000e-02 0.00000000e+00]\n",
            " [1.00000000e+00 1.99999999e-06 0.00000000e+00]\n",
            " [1.00000000e+00 9.23225999e-01 1.00000000e+00]\n",
            " [0.00000000e+00 2.29806006e-01 0.00000000e+00]\n",
            " [0.00000000e+00 9.54146028e-01 1.00000000e+00]\n",
            " [1.00000000e+00 5.23000024e-04 0.00000000e+00]\n",
            " [0.00000000e+00 3.61629985e-02 0.00000000e+00]]\n",
            "\n",
            "\n",
            "\\Testing: [[1.00000000e+00 2.49760002e-02 0.00000000e+00]\n",
            " [1.00000000e+00 9.40000027e-05 0.00000000e+00]\n",
            " [1.00000000e+00 3.02646011e-01 0.00000000e+00]\n",
            " [1.00000000e+00 9.99998987e-01 1.00000000e+00]\n",
            " [1.00000000e+00 2.63431996e-01 0.00000000e+00]\n",
            " [0.00000000e+00 3.94500010e-02 0.00000000e+00]\n",
            " [1.00000000e+00 9.15000029e-03 0.00000000e+00]\n",
            " [1.00000000e+00 3.00000011e-06 0.00000000e+00]\n",
            " [0.00000000e+00 9.94996011e-01 1.00000000e+00]\n",
            " [1.00000000e+00 1.20000004e-05 0.00000000e+00]\n",
            " [1.00000000e+00 2.63800006e-03 0.00000000e+00]\n",
            " [0.00000000e+00 3.42415988e-01 0.00000000e+00]\n",
            " [1.00000000e+00 9.68500040e-03 0.00000000e+00]\n",
            " [1.00000000e+00 4.72219996e-02 0.00000000e+00]\n",
            " [0.00000000e+00 9.64401007e-01 1.00000000e+00]\n",
            " [1.00000000e+00 4.52100020e-03 0.00000000e+00]\n",
            " [1.00000000e+00 6.57700002e-03 0.00000000e+00]\n",
            " [0.00000000e+00 2.79799988e-03 0.00000000e+00]\n",
            " [1.00000000e+00 9.96372998e-01 1.00000000e+00]\n",
            " [0.00000000e+00 7.86999997e-04 0.00000000e+00]\n",
            " [0.00000000e+00 6.99770004e-02 0.00000000e+00]\n",
            " [0.00000000e+00 3.00000011e-06 0.00000000e+00]\n",
            " [1.00000000e+00 6.45370036e-02 0.00000000e+00]\n",
            " [1.00000000e+00 6.10835016e-01 1.00000000e+00]\n",
            " [1.00000000e+00 5.69400005e-03 0.00000000e+00]\n",
            " [0.00000000e+00 3.67029011e-01 0.00000000e+00]\n",
            " [0.00000000e+00 6.99910000e-02 0.00000000e+00]\n",
            " [0.00000000e+00 2.33610004e-01 0.00000000e+00]\n",
            " [0.00000000e+00 8.23391020e-01 1.00000000e+00]\n",
            " [0.00000000e+00 9.66566026e-01 1.00000000e+00]\n",
            " [0.00000000e+00 9.99999997e-07 0.00000000e+00]\n",
            " [1.00000000e+00 3.86589989e-02 0.00000000e+00]\n",
            " [1.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
            " [1.00000000e+00 9.00000032e-06 0.00000000e+00]\n",
            " [0.00000000e+00 6.00000021e-06 0.00000000e+00]\n",
            " [1.00000000e+00 5.77999977e-04 0.00000000e+00]\n",
            " [0.00000000e+00 8.27879980e-02 0.00000000e+00]\n",
            " [1.00000000e+00 1.40424997e-01 0.00000000e+00]\n",
            " [0.00000000e+00 2.09999998e-05 0.00000000e+00]\n",
            " [0.00000000e+00 0.00000000e+00 0.00000000e+00]]\n",
            "Training loss:   134.200844\n",
            "\n",
            "\n",
            "\n",
            "Training: labels: [[0.         0.53126502 1.        ]\n",
            " [1.         0.55622399 1.        ]\n",
            " [1.         0.40743101 0.        ]\n",
            " [0.         0.60043597 1.        ]\n",
            " [0.         0.33057299 0.        ]\n",
            " [1.         0.30612299 0.        ]\n",
            " [1.         0.36116499 0.        ]\n",
            " [0.         0.420627   0.        ]\n",
            " [1.         0.49134699 0.        ]\n",
            " [1.         0.37858099 0.        ]\n",
            " [0.         0.538858   1.        ]\n",
            " [0.         0.27183101 0.        ]\n",
            " [0.         0.28782901 0.        ]\n",
            " [0.         0.25470099 0.        ]\n",
            " [1.         0.20186099 0.        ]\n",
            " [1.         0.521052   1.        ]\n",
            " [0.         0.39209199 0.        ]\n",
            " [0.         0.18845899 0.        ]\n",
            " [1.         0.52512598 1.        ]\n",
            " [0.         0.255308   0.        ]]\n",
            "\n",
            "\n",
            "\\Testing: [[1.         0.29655001 0.        ]\n",
            " [1.         0.56490999 1.        ]\n",
            " [1.         0.21447501 0.        ]\n",
            " [1.         0.54303002 1.        ]\n",
            " [1.         0.41343001 0.        ]\n",
            " [0.         0.50020099 1.        ]\n",
            " [1.         0.62584502 1.        ]\n",
            " [1.         0.48655    0.        ]\n",
            " [0.         0.53952599 1.        ]\n",
            " [1.         0.36632901 0.        ]\n",
            " [1.         0.42546099 0.        ]\n",
            " [0.         0.41415599 0.        ]\n",
            " [1.         0.53695101 1.        ]\n",
            " [1.         0.72957599 1.        ]\n",
            " [0.         0.51951098 1.        ]\n",
            " [1.         0.59710598 1.        ]\n",
            " [1.         0.56934398 1.        ]\n",
            " [0.         0.49574399 0.        ]\n",
            " [1.         0.199995   0.        ]\n",
            " [0.         0.70975697 1.        ]\n",
            " [0.         0.52241999 1.        ]\n",
            " [0.         0.54908103 1.        ]\n",
            " [1.         0.62080002 1.        ]\n",
            " [1.         0.73035002 1.        ]\n",
            " [1.         0.30777401 0.        ]\n",
            " [0.         0.55824602 1.        ]\n",
            " [0.         0.364117   0.        ]\n",
            " [0.         0.57891101 1.        ]\n",
            " [0.         0.677347   1.        ]\n",
            " [0.         0.20438699 0.        ]\n",
            " [0.         0.70712501 1.        ]\n",
            " [1.         0.74419701 1.        ]\n",
            " [1.         0.67069799 1.        ]\n",
            " [1.         0.69566202 1.        ]\n",
            " [0.         0.83464599 1.        ]\n",
            " [1.         0.49237299 0.        ]\n",
            " [0.         0.54191798 1.        ]\n",
            " [1.         0.57141    1.        ]\n",
            " [0.         0.34566399 0.        ]\n",
            " [0.         0.44736001 0.        ]]\n",
            "Training loss:   130.709912\n",
            "\n",
            "\n",
            "\n",
            "Training: labels: [[0.         0.38232201 0.        ]\n",
            " [1.         0.243113   0.        ]\n",
            " [1.         0.487757   0.        ]\n",
            " [0.         0.52509701 1.        ]\n",
            " [0.         0.45055699 0.        ]\n",
            " [1.         0.127656   0.        ]\n",
            " [1.         0.38245201 0.        ]\n",
            " [0.         0.51671201 1.        ]\n",
            " [1.         0.314042   0.        ]\n",
            " [1.         0.386415   0.        ]\n",
            " [0.         0.52438003 1.        ]\n",
            " [0.         0.31159699 0.        ]\n",
            " [0.         0.48787999 0.        ]\n",
            " [0.         0.39824101 0.        ]\n",
            " [1.         0.48945099 0.        ]\n",
            " [1.         0.188537   0.        ]\n",
            " [0.         0.34214801 0.        ]\n",
            " [0.         0.55458599 1.        ]\n",
            " [1.         0.61697799 1.        ]\n",
            " [0.         0.54773903 1.        ]]\n",
            "\n",
            "\n",
            "\\Testing: [[1.         0.37121999 0.        ]\n",
            " [1.         0.36690199 0.        ]\n",
            " [1.         0.36314499 0.        ]\n",
            " [1.         0.61584997 1.        ]\n",
            " [1.         0.65017903 1.        ]\n",
            " [0.         0.50315601 1.        ]\n",
            " [1.         0.41412401 0.        ]\n",
            " [1.         0.19136199 0.        ]\n",
            " [0.         0.479031   0.        ]\n",
            " [1.         0.466701   0.        ]\n",
            " [1.         0.657785   1.        ]\n",
            " [0.         0.57749897 1.        ]\n",
            " [1.         0.39390901 0.        ]\n",
            " [1.         0.61252701 1.        ]\n",
            " [0.         0.51867598 1.        ]\n",
            " [1.         0.640001   1.        ]\n",
            " [1.         0.247408   0.        ]\n",
            " [0.         0.43913299 0.        ]\n",
            " [1.         0.58672202 1.        ]\n",
            " [0.         0.55159497 1.        ]\n",
            " [0.         0.52125299 1.        ]\n",
            " [0.         0.73614401 1.        ]\n",
            " [1.         0.38315201 0.        ]\n",
            " [1.         0.36299101 0.        ]\n",
            " [1.         0.53716803 1.        ]\n",
            " [0.         0.72122598 1.        ]\n",
            " [0.         0.30057999 0.        ]\n",
            " [0.         0.29903999 0.        ]\n",
            " [0.         0.415636   0.        ]\n",
            " [0.         0.68483299 1.        ]\n",
            " [0.         0.36756599 0.        ]\n",
            " [1.         0.64950198 1.        ]\n",
            " [1.         0.478129   0.        ]\n",
            " [1.         0.45195699 0.        ]\n",
            " [0.         0.46516901 0.        ]\n",
            " [1.         0.67284799 1.        ]\n",
            " [0.         0.81995302 1.        ]\n",
            " [1.         0.54954302 1.        ]\n",
            " [0.         0.47722    0.        ]\n",
            " [0.         0.55153602 1.        ]]\n",
            "Training loss:   130.153389\n",
            "\n",
            "\n",
            "\n",
            "Training: labels: [[0.         0.98536599 1.        ]\n",
            " [1.         0.916026   1.        ]\n",
            " [1.         0.88138801 1.        ]\n",
            " [0.         0.97769201 1.        ]\n",
            " [0.         0.88919097 1.        ]\n",
            " [1.         0.12119    0.        ]\n",
            " [1.         0.89991403 1.        ]\n",
            " [0.         0.72747999 1.        ]\n",
            " [1.         0.73440999 1.        ]\n",
            " [1.         0.090605   0.        ]\n",
            " [0.         0.72067201 1.        ]\n",
            " [0.         0.24602599 0.        ]\n",
            " [0.         0.85002398 1.        ]\n",
            " [0.         0.62658    1.        ]\n",
            " [1.         0.91093099 1.        ]\n",
            " [1.         0.907682   1.        ]\n",
            " [0.         0.86679697 1.        ]\n",
            " [0.         0.80518299 1.        ]\n",
            " [1.         0.96489102 1.        ]\n",
            " [0.         0.94738799 1.        ]]\n",
            "\n",
            "\n",
            "\\Testing: [[1.         0.814794   1.        ]\n",
            " [1.         0.84934902 1.        ]\n",
            " [1.         0.90928102 1.        ]\n",
            " [1.         0.728576   1.        ]\n",
            " [1.         0.94992399 1.        ]\n",
            " [0.         0.63370198 1.        ]\n",
            " [1.         0.895796   1.        ]\n",
            " [1.         0.86947101 1.        ]\n",
            " [0.         0.88504398 1.        ]\n",
            " [1.         0.48662999 0.        ]\n",
            " [1.         0.41835299 0.        ]\n",
            " [0.         0.72987801 1.        ]\n",
            " [1.         0.295636   0.        ]\n",
            " [1.         0.48699    0.        ]\n",
            " [0.         0.63472903 1.        ]\n",
            " [1.         0.199626   0.        ]\n",
            " [1.         0.742459   1.        ]\n",
            " [0.         0.19982301 0.        ]\n",
            " [1.         0.86302102 1.        ]\n",
            " [0.         0.85736102 1.        ]\n",
            " [0.         0.27240801 0.        ]\n",
            " [0.         0.238976   0.        ]\n",
            " [1.         0.670708   1.        ]\n",
            " [1.         0.62604803 1.        ]\n",
            " [1.         0.89989603 1.        ]\n",
            " [0.         0.82921302 1.        ]\n",
            " [0.         0.67422801 1.        ]\n",
            " [0.         0.77757698 1.        ]\n",
            " [0.         0.50314802 1.        ]\n",
            " [0.         0.56373298 1.        ]\n",
            " [0.         0.048914   0.        ]\n",
            " [1.         0.371685   0.        ]\n",
            " [1.         0.23505899 0.        ]\n",
            " [1.         0.77036601 1.        ]\n",
            " [0.         0.27497101 0.        ]\n",
            " [1.         0.424005   0.        ]\n",
            " [0.         0.36939001 0.        ]\n",
            " [1.         0.64522803 1.        ]\n",
            " [0.         0.90593803 1.        ]\n",
            " [0.         0.67861199 1.        ]]\n",
            "Training loss:   127.887543\n",
            "\n",
            "\n",
            "\n",
            "Training: labels: [[0.         0.67150199 1.        ]\n",
            " [1.         0.29268199 0.        ]\n",
            " [1.         0.46045399 0.        ]\n",
            " [0.         0.701747   1.        ]\n",
            " [0.         0.22346701 0.        ]\n",
            " [1.         0.40193099 0.        ]\n",
            " [1.         0.43203601 0.        ]\n",
            " [0.         0.39937299 0.        ]\n",
            " [1.         0.48112801 0.        ]\n",
            " [1.         0.390609   0.        ]\n",
            " [0.         0.107637   0.        ]\n",
            " [0.         0.26190299 0.        ]\n",
            " [0.         0.76861    1.        ]\n",
            " [0.         0.58977801 1.        ]\n",
            " [1.         0.447216   0.        ]\n",
            " [1.         0.57134598 1.        ]\n",
            " [0.         0.71551901 1.        ]\n",
            " [0.         0.84289002 1.        ]\n",
            " [1.         0.490408   0.        ]\n",
            " [0.         0.61215699 1.        ]]\n",
            "\n",
            "\n",
            "\\Testing: [[1.         0.19543301 0.        ]\n",
            " [1.         0.49380699 0.        ]\n",
            " [1.         0.129933   0.        ]\n",
            " [1.         0.23954201 0.        ]\n",
            " [1.         0.065133   0.        ]\n",
            " [0.         0.45763299 0.        ]\n",
            " [1.         0.382357   0.        ]\n",
            " [1.         0.524198   1.        ]\n",
            " [0.         0.041234   0.        ]\n",
            " [1.         0.41782701 0.        ]\n",
            " [1.         0.26729199 0.        ]\n",
            " [0.         0.076562   0.        ]\n",
            " [1.         0.51934803 1.        ]\n",
            " [1.         0.59229302 1.        ]\n",
            " [0.         0.153713   0.        ]\n",
            " [1.         0.58068502 1.        ]\n",
            " [1.         0.12912101 0.        ]\n",
            " [0.         0.67411298 1.        ]\n",
            " [1.         0.25588799 0.        ]\n",
            " [0.         0.239738   0.        ]\n",
            " [0.         0.17604201 0.        ]\n",
            " [0.         0.34151    0.        ]\n",
            " [1.         0.517744   1.        ]\n",
            " [1.         0.227707   0.        ]\n",
            " [1.         0.43899101 0.        ]\n",
            " [0.         0.64430702 1.        ]\n",
            " [0.         0.317563   0.        ]\n",
            " [0.         0.58211601 1.        ]\n",
            " [0.         0.35676399 0.        ]\n",
            " [0.         0.17615201 0.        ]\n",
            " [0.         0.23417901 0.        ]\n",
            " [1.         0.40506199 0.        ]\n",
            " [1.         0.328096   0.        ]\n",
            " [1.         0.66397399 1.        ]\n",
            " [0.         0.63013703 1.        ]\n",
            " [1.         0.341674   0.        ]\n",
            " [0.         0.198337   0.        ]\n",
            " [1.         0.67989099 1.        ]\n",
            " [0.         0.109381   0.        ]\n",
            " [0.         0.57035202 1.        ]]\n",
            "Training loss:   163.27295\n",
            "\n",
            "\n",
            "\n",
            "Training: labels: [[0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
            " [1.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
            " [1.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
            " [0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
            " [0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
            " [1.00000000e+00 2.73000012e-04 0.00000000e+00]\n",
            " [1.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
            " [0.00000000e+00 1.40000002e-05 0.00000000e+00]\n",
            " [1.00000000e+00 8.59274983e-01 1.00000000e+00]\n",
            " [1.00000000e+00 1.29299995e-03 0.00000000e+00]\n",
            " [0.00000000e+00 9.80197012e-01 1.00000000e+00]\n",
            " [0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
            " [0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
            " [0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
            " [1.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
            " [1.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
            " [0.00000000e+00 9.73500032e-03 0.00000000e+00]\n",
            " [0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
            " [1.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
            " [0.00000000e+00 3.38999991e-04 0.00000000e+00]]\n",
            "\n",
            "\n",
            "\\Testing: [[1.00000000e+00 6.19999992e-05 0.00000000e+00]\n",
            " [1.00000000e+00 2.90000007e-05 0.00000000e+00]\n",
            " [1.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
            " [1.00000000e+00 3.70000016e-05 0.00000000e+00]\n",
            " [1.00000000e+00 8.66600033e-03 0.00000000e+00]\n",
            " [0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
            " [1.00000000e+00 2.90000007e-05 0.00000000e+00]\n",
            " [1.00000000e+00 5.09999991e-05 0.00000000e+00]\n",
            " [0.00000000e+00 3.59000009e-03 0.00000000e+00]\n",
            " [1.00000000e+00 2.11999999e-04 0.00000000e+00]\n",
            " [1.00000000e+00 3.79700004e-03 0.00000000e+00]\n",
            " [0.00000000e+00 2.39999994e-04 0.00000000e+00]\n",
            " [1.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
            " [1.00000000e+00 9.99999997e-07 0.00000000e+00]\n",
            " [0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
            " [1.00000000e+00 3.00000011e-06 0.00000000e+00]\n",
            " [1.00000000e+00 8.29999990e-05 0.00000000e+00]\n",
            " [0.00000000e+00 2.68474996e-01 0.00000000e+00]\n",
            " [1.00000000e+00 7.10000022e-05 0.00000000e+00]\n",
            " [0.00000000e+00 1.32171005e-01 0.00000000e+00]\n",
            " [0.00000000e+00 4.95300023e-03 0.00000000e+00]\n",
            " [0.00000000e+00 1.94200000e-03 0.00000000e+00]\n",
            " [1.00000000e+00 1.79200002e-03 0.00000000e+00]\n",
            " [1.00000000e+00 1.31045997e-01 0.00000000e+00]\n",
            " [1.00000000e+00 1.30200002e-03 0.00000000e+00]\n",
            " [0.00000000e+00 1.23999998e-04 0.00000000e+00]\n",
            " [0.00000000e+00 8.46100040e-03 0.00000000e+00]\n",
            " [0.00000000e+00 5.50000004e-05 0.00000000e+00]\n",
            " [0.00000000e+00 1.61620006e-02 0.00000000e+00]\n",
            " [0.00000000e+00 5.82000008e-04 0.00000000e+00]\n",
            " [0.00000000e+00 5.12569994e-02 0.00000000e+00]\n",
            " [1.00000000e+00 2.59999997e-05 0.00000000e+00]\n",
            " [1.00000000e+00 4.88209985e-02 0.00000000e+00]\n",
            " [1.00000000e+00 4.29000007e-04 0.00000000e+00]\n",
            " [0.00000000e+00 3.70360017e-02 0.00000000e+00]\n",
            " [1.00000000e+00 7.36659989e-02 0.00000000e+00]\n",
            " [0.00000000e+00 4.87999991e-04 0.00000000e+00]\n",
            " [1.00000000e+00 9.99999997e-07 0.00000000e+00]\n",
            " [0.00000000e+00 6.64300006e-03 0.00000000e+00]\n",
            " [0.00000000e+00 2.95000005e-04 0.00000000e+00]]\n",
            "Training loss:   262.206699\n",
            "\n",
            "\n",
            "\n",
            "Training: labels: [[0.         0.30481699 0.        ]\n",
            " [1.         0.25357601 0.        ]\n",
            " [1.         0.95045602 1.        ]\n",
            " [0.         0.91012102 1.        ]\n",
            " [0.         0.45194599 0.        ]\n",
            " [1.         0.79561502 1.        ]\n",
            " [1.         0.99994898 1.        ]\n",
            " [0.         0.40985101 0.        ]\n",
            " [1.         0.83306098 1.        ]\n",
            " [1.         0.91905999 1.        ]\n",
            " [0.         0.99847901 1.        ]\n",
            " [0.         0.999924   1.        ]\n",
            " [0.         0.937428   1.        ]\n",
            " [0.         0.70626801 1.        ]\n",
            " [1.         0.032169   0.        ]\n",
            " [1.         0.816724   1.        ]\n",
            " [0.         0.99898201 1.        ]\n",
            " [0.         0.99968302 1.        ]\n",
            " [1.         0.96164    1.        ]\n",
            " [0.         0.99991    1.        ]]\n",
            "\n",
            "\n",
            "\\Testing: [[1.         0.99733502 1.        ]\n",
            " [1.         0.99751502 1.        ]\n",
            " [1.         0.99948299 1.        ]\n",
            " [1.         0.996584   1.        ]\n",
            " [1.         0.93462801 1.        ]\n",
            " [0.         0.99946898 1.        ]\n",
            " [1.         0.99598902 1.        ]\n",
            " [1.         0.98008001 1.        ]\n",
            " [0.         0.99344301 1.        ]\n",
            " [1.         0.98780698 1.        ]\n",
            " [1.         0.49707299 0.        ]\n",
            " [0.         0.98065799 1.        ]\n",
            " [1.         0.99328601 1.        ]\n",
            " [1.         0.099749   0.        ]\n",
            " [0.         0.997289   1.        ]\n",
            " [1.         0.97824597 1.        ]\n",
            " [1.         0.99361801 1.        ]\n",
            " [0.         0.98623103 1.        ]\n",
            " [1.         0.92819798 1.        ]\n",
            " [0.         0.99937701 1.        ]\n",
            " [0.         0.99865001 1.        ]\n",
            " [0.         0.89469397 1.        ]\n",
            " [1.         0.99983299 1.        ]\n",
            " [1.         0.99946398 1.        ]\n",
            " [1.         0.31767601 0.        ]\n",
            " [0.         0.88314599 1.        ]\n",
            " [0.         0.98116302 1.        ]\n",
            " [0.         0.906578   1.        ]\n",
            " [0.         0.69238001 1.        ]\n",
            " [0.         0.91735703 1.        ]\n",
            " [0.         0.99913198 1.        ]\n",
            " [1.         0.98590499 1.        ]\n",
            " [1.         0.99991298 1.        ]\n",
            " [1.         0.066026   0.        ]\n",
            " [0.         0.99863702 1.        ]\n",
            " [1.         0.33636999 0.        ]\n",
            " [0.         0.99933499 1.        ]\n",
            " [1.         0.96020901 1.        ]\n",
            " [0.         0.97886997 1.        ]\n",
            " [0.         0.62053698 1.        ]]\n",
            "Training loss:   131.504837\n",
            "\n",
            "\n",
            "\n",
            "Training: labels: [[0.         0.749394   1.        ]\n",
            " [1.         0.60104299 1.        ]\n",
            " [1.         0.83217502 1.        ]\n",
            " [0.         0.80668098 1.        ]\n",
            " [0.         0.52551198 1.        ]\n",
            " [1.         0.080945   0.        ]\n",
            " [1.         0.83468097 1.        ]\n",
            " [0.         0.95037699 1.        ]\n",
            " [1.         0.90839702 1.        ]\n",
            " [1.         0.42595699 0.        ]\n",
            " [0.         0.35455999 0.        ]\n",
            " [0.         0.75770599 1.        ]\n",
            " [0.         0.59021002 1.        ]\n",
            " [0.         0.81899202 1.        ]\n",
            " [1.         0.485852   0.        ]\n",
            " [1.         0.84777802 1.        ]\n",
            " [0.         0.64664602 1.        ]\n",
            " [0.         0.096607   0.        ]\n",
            " [1.         0.45928401 0.        ]\n",
            " [0.         0.19754501 0.        ]]\n",
            "\n",
            "\n",
            "\\Testing: [[1.         0.278918   0.        ]\n",
            " [1.         0.66587597 1.        ]\n",
            " [1.         0.75329202 1.        ]\n",
            " [1.         0.18132401 0.        ]\n",
            " [1.         0.99459302 1.        ]\n",
            " [0.         0.20061    0.        ]\n",
            " [1.         0.94891602 1.        ]\n",
            " [1.         0.92134202 1.        ]\n",
            " [0.         0.64362001 1.        ]\n",
            " [1.         0.789666   1.        ]\n",
            " [1.         0.148164   0.        ]\n",
            " [0.         0.80572897 1.        ]\n",
            " [1.         0.33960599 0.        ]\n",
            " [1.         0.72239    1.        ]\n",
            " [0.         0.78785199 1.        ]\n",
            " [1.         0.48470101 0.        ]\n",
            " [1.         0.58699799 1.        ]\n",
            " [0.         0.400291   0.        ]\n",
            " [1.         0.653611   1.        ]\n",
            " [0.         0.97175902 1.        ]\n",
            " [0.         0.193718   0.        ]\n",
            " [0.         0.67850202 1.        ]\n",
            " [1.         0.155066   0.        ]\n",
            " [1.         0.109303   0.        ]\n",
            " [1.         0.82698703 1.        ]\n",
            " [0.         0.55941498 1.        ]\n",
            " [0.         0.62969702 1.        ]\n",
            " [0.         0.33473501 0.        ]\n",
            " [0.         0.95948797 1.        ]\n",
            " [0.         0.56682199 1.        ]\n",
            " [0.         0.178794   0.        ]\n",
            " [1.         0.19362099 0.        ]\n",
            " [1.         0.81381601 1.        ]\n",
            " [1.         0.64378601 1.        ]\n",
            " [0.         0.96157497 1.        ]\n",
            " [1.         0.89376098 1.        ]\n",
            " [0.         0.89735198 1.        ]\n",
            " [1.         0.51455402 1.        ]\n",
            " [0.         0.142599   0.        ]\n",
            " [0.         0.14972299 0.        ]]\n",
            "Training loss:   128.602313\n",
            "\n",
            "\n",
            "\n",
            "Training: labels: [[0.         0.79733801 1.        ]\n",
            " [1.         0.51817203 1.        ]\n",
            " [1.         0.53753    1.        ]\n",
            " [0.         0.200838   0.        ]\n",
            " [0.         0.33991501 0.        ]\n",
            " [1.         0.892645   1.        ]\n",
            " [1.         0.69624603 1.        ]\n",
            " [0.         0.324184   0.        ]\n",
            " [1.         0.62300903 1.        ]\n",
            " [1.         0.50502402 1.        ]\n",
            " [0.         0.12359    0.        ]\n",
            " [0.         0.35570201 0.        ]\n",
            " [0.         0.63995099 1.        ]\n",
            " [0.         0.31062701 0.        ]\n",
            " [1.         0.26963001 0.        ]\n",
            " [1.         0.075014   0.        ]\n",
            " [0.         0.55131799 1.        ]\n",
            " [0.         0.24567901 0.        ]\n",
            " [1.         0.39393899 0.        ]\n",
            " [0.         0.60162598 1.        ]]\n",
            "\n",
            "\n",
            "\\Testing: [[1.         0.60505003 1.        ]\n",
            " [1.         0.27302101 0.        ]\n",
            " [1.         0.52781999 1.        ]\n",
            " [1.         0.25380701 0.        ]\n",
            " [1.         0.159187   0.        ]\n",
            " [0.         0.62935197 1.        ]\n",
            " [1.         0.142336   0.        ]\n",
            " [1.         0.446143   0.        ]\n",
            " [0.         0.18437    0.        ]\n",
            " [1.         0.194998   0.        ]\n",
            " [1.         0.217693   0.        ]\n",
            " [0.         0.43091601 0.        ]\n",
            " [1.         0.29950801 0.        ]\n",
            " [1.         0.51497799 1.        ]\n",
            " [0.         0.35719299 0.        ]\n",
            " [1.         0.19851799 0.        ]\n",
            " [1.         0.39552099 0.        ]\n",
            " [0.         0.36276099 0.        ]\n",
            " [1.         0.36352    0.        ]\n",
            " [0.         0.38974199 0.        ]\n",
            " [0.         0.67985702 1.        ]\n",
            " [0.         0.137594   0.        ]\n",
            " [1.         0.27691999 0.        ]\n",
            " [1.         0.29027301 0.        ]\n",
            " [1.         0.139082   0.        ]\n",
            " [0.         0.55934399 1.        ]\n",
            " [0.         0.11881    0.        ]\n",
            " [0.         0.06432    0.        ]\n",
            " [0.         0.45811599 0.        ]\n",
            " [0.         0.35460401 0.        ]\n",
            " [0.         0.035754   0.        ]\n",
            " [1.         0.54288799 1.        ]\n",
            " [1.         0.35863101 0.        ]\n",
            " [1.         0.59688199 1.        ]\n",
            " [0.         0.201546   0.        ]\n",
            " [1.         0.22515    0.        ]\n",
            " [0.         0.33777601 0.        ]\n",
            " [1.         0.25579399 0.        ]\n",
            " [0.         0.38744301 0.        ]\n",
            " [0.         0.56032199 1.        ]]\n",
            "Training loss:   1664553.118859\n",
            "\n",
            "\n",
            "\n",
            "Training: labels: [[0.00000000e+00 1.02099997e-03 0.00000000e+00]\n",
            " [1.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
            " [1.00000000e+00 9.96155977e-01 1.00000000e+00]\n",
            " [0.00000000e+00 1.47100003e-03 0.00000000e+00]\n",
            " [0.00000000e+00 9.99948978e-01 1.00000000e+00]\n",
            " [1.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
            " [1.00000000e+00 1.00000000e+00 1.00000000e+00]\n",
            " [0.00000000e+00 9.04438972e-01 1.00000000e+00]\n",
            " [1.00000000e+00 1.00000000e+00 1.00000000e+00]\n",
            " [1.00000000e+00 9.91680026e-01 1.00000000e+00]\n",
            " [0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
            " [0.00000000e+00 3.02779991e-02 0.00000000e+00]\n",
            " [0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
            " [0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
            " [1.00000000e+00 7.99999998e-06 0.00000000e+00]\n",
            " [1.00000000e+00 1.00000000e+00 1.00000000e+00]\n",
            " [0.00000000e+00 9.99993026e-01 1.00000000e+00]\n",
            " [0.00000000e+00 2.40759000e-01 0.00000000e+00]\n",
            " [1.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
            " [0.00000000e+00 9.99999997e-07 0.00000000e+00]]\n",
            "\n",
            "\n",
            "\\Testing: [[1.00000000e+00 1.91110000e-02 0.00000000e+00]\n",
            " [1.00000000e+00 3.79999983e-05 0.00000000e+00]\n",
            " [1.00000000e+00 3.79038006e-01 0.00000000e+00]\n",
            " [1.00000000e+00 5.80000014e-05 0.00000000e+00]\n",
            " [1.00000000e+00 1.00000000e+00 1.00000000e+00]\n",
            " [0.00000000e+00 5.08844018e-01 1.00000000e+00]\n",
            " [1.00000000e+00 3.20599996e-03 0.00000000e+00]\n",
            " [1.00000000e+00 4.41800011e-03 0.00000000e+00]\n",
            " [0.00000000e+00 9.98301029e-01 1.00000000e+00]\n",
            " [1.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
            " [1.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
            " [0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
            " [1.00000000e+00 8.48842978e-01 1.00000000e+00]\n",
            " [1.00000000e+00 2.26883993e-01 0.00000000e+00]\n",
            " [0.00000000e+00 3.54247987e-01 0.00000000e+00]\n",
            " [1.00000000e+00 7.15999980e-04 0.00000000e+00]\n",
            " [1.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
            " [0.00000000e+00 8.58000014e-04 0.00000000e+00]\n",
            " [1.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
            " [0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
            " [0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
            " [0.00000000e+00 9.99993026e-01 1.00000000e+00]\n",
            " [1.00000000e+00 9.92187023e-01 1.00000000e+00]\n",
            " [1.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
            " [1.00000000e+00 1.15000003e-04 0.00000000e+00]\n",
            " [0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
            " [0.00000000e+00 1.33389998e-02 0.00000000e+00]\n",
            " [0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
            " [0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
            " [0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
            " [0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
            " [1.00000000e+00 3.48299998e-03 0.00000000e+00]\n",
            " [1.00000000e+00 1.49999996e-05 0.00000000e+00]\n",
            " [1.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
            " [0.00000000e+00 7.35373974e-01 1.00000000e+00]\n",
            " [1.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
            " [0.00000000e+00 1.00000000e+00 1.00000000e+00]\n",
            " [1.00000000e+00 2.96700001e-03 0.00000000e+00]\n",
            " [0.00000000e+00 9.94772017e-01 1.00000000e+00]\n",
            " [0.00000000e+00 3.01100011e-03 0.00000000e+00]]\n",
            "Training loss:   163.158923\n",
            "\n",
            "\n",
            "\n",
            "Training: labels: [[0.00000000e+00 9.44000029e-04 0.00000000e+00]\n",
            " [1.00000000e+00 8.48099962e-03 0.00000000e+00]\n",
            " [1.00000000e+00 8.06100015e-03 0.00000000e+00]\n",
            " [0.00000000e+00 9.24735010e-01 1.00000000e+00]\n",
            " [0.00000000e+00 4.72990014e-02 0.00000000e+00]\n",
            " [1.00000000e+00 1.78855002e-01 0.00000000e+00]\n",
            " [1.00000000e+00 6.29999995e-05 0.00000000e+00]\n",
            " [0.00000000e+00 2.61999987e-04 0.00000000e+00]\n",
            " [1.00000000e+00 9.57243979e-01 1.00000000e+00]\n",
            " [1.00000000e+00 8.89000017e-04 0.00000000e+00]\n",
            " [0.00000000e+00 1.99999999e-06 0.00000000e+00]\n",
            " [0.00000000e+00 1.59023002e-01 0.00000000e+00]\n",
            " [0.00000000e+00 1.18809998e-01 0.00000000e+00]\n",
            " [0.00000000e+00 6.42100023e-03 0.00000000e+00]\n",
            " [1.00000000e+00 5.72999998e-04 0.00000000e+00]\n",
            " [1.00000000e+00 1.08460002e-02 0.00000000e+00]\n",
            " [0.00000000e+00 2.96800002e-03 0.00000000e+00]\n",
            " [0.00000000e+00 1.04999999e-04 0.00000000e+00]\n",
            " [1.00000000e+00 9.95953977e-01 1.00000000e+00]\n",
            " [0.00000000e+00 9.33727980e-01 1.00000000e+00]]\n",
            "\n",
            "\n",
            "\\Testing: [[1.00000000e+00 8.40036988e-01 1.00000000e+00]\n",
            " [1.00000000e+00 1.72999993e-04 0.00000000e+00]\n",
            " [1.00000000e+00 1.19209997e-02 0.00000000e+00]\n",
            " [1.00000000e+00 4.85760011e-02 0.00000000e+00]\n",
            " [1.00000000e+00 4.92913008e-01 0.00000000e+00]\n",
            " [0.00000000e+00 4.99875009e-01 0.00000000e+00]\n",
            " [1.00000000e+00 1.02999998e-04 0.00000000e+00]\n",
            " [1.00000000e+00 9.88038003e-01 1.00000000e+00]\n",
            " [0.00000000e+00 5.23599982e-03 0.00000000e+00]\n",
            " [1.00000000e+00 3.96999996e-04 0.00000000e+00]\n",
            " [1.00000000e+00 1.67000003e-03 0.00000000e+00]\n",
            " [0.00000000e+00 2.83410009e-02 0.00000000e+00]\n",
            " [1.00000000e+00 9.05632019e-01 1.00000000e+00]\n",
            " [1.00000000e+00 4.91905987e-01 0.00000000e+00]\n",
            " [0.00000000e+00 1.91300001e-03 0.00000000e+00]\n",
            " [1.00000000e+00 8.90000010e-05 0.00000000e+00]\n",
            " [1.00000000e+00 1.29999999e-05 0.00000000e+00]\n",
            " [0.00000000e+00 4.34107989e-01 0.00000000e+00]\n",
            " [1.00000000e+00 1.07370000e-02 0.00000000e+00]\n",
            " [0.00000000e+00 2.00366005e-01 0.00000000e+00]\n",
            " [0.00000000e+00 5.00084996e-01 1.00000000e+00]\n",
            " [0.00000000e+00 9.92012024e-01 1.00000000e+00]\n",
            " [1.00000000e+00 8.21835995e-01 1.00000000e+00]\n",
            " [1.00000000e+00 9.51129973e-01 1.00000000e+00]\n",
            " [1.00000000e+00 9.42649007e-01 1.00000000e+00]\n",
            " [0.00000000e+00 2.33849995e-02 0.00000000e+00]\n",
            " [0.00000000e+00 7.98999972e-04 0.00000000e+00]\n",
            " [0.00000000e+00 8.36000021e-04 0.00000000e+00]\n",
            " [0.00000000e+00 3.67820002e-02 0.00000000e+00]\n",
            " [0.00000000e+00 5.80000014e-05 0.00000000e+00]\n",
            " [0.00000000e+00 4.23720986e-01 0.00000000e+00]\n",
            " [1.00000000e+00 1.46220000e-02 0.00000000e+00]\n",
            " [1.00000000e+00 3.21873009e-01 0.00000000e+00]\n",
            " [1.00000000e+00 9.79999968e-05 0.00000000e+00]\n",
            " [0.00000000e+00 8.00365984e-01 1.00000000e+00]\n",
            " [1.00000000e+00 8.37890029e-01 1.00000000e+00]\n",
            " [0.00000000e+00 8.61865997e-01 1.00000000e+00]\n",
            " [1.00000000e+00 4.84732002e-01 0.00000000e+00]\n",
            " [0.00000000e+00 9.97321010e-01 1.00000000e+00]\n",
            " [0.00000000e+00 4.12000008e-02 0.00000000e+00]]\n",
            "Training loss:   155.120585\n",
            "\n",
            "\n",
            "\n",
            "Training: labels: [[0.         0.93558103 1.        ]\n",
            " [1.         0.97289503 1.        ]\n",
            " [1.         0.121698   0.        ]\n",
            " [0.         0.87899399 1.        ]\n",
            " [0.         0.003417   0.        ]\n",
            " [1.         0.285705   0.        ]\n",
            " [1.         0.65184098 1.        ]\n",
            " [0.         0.141744   0.        ]\n",
            " [1.         0.25569499 0.        ]\n",
            " [1.         0.790627   1.        ]\n",
            " [0.         0.53796798 1.        ]\n",
            " [0.         0.95646    1.        ]\n",
            " [0.         0.105871   0.        ]\n",
            " [0.         0.396247   0.        ]\n",
            " [1.         0.16478699 0.        ]\n",
            " [1.         0.72335702 1.        ]\n",
            " [0.         0.54627699 1.        ]\n",
            " [0.         0.52873898 1.        ]\n",
            " [1.         0.008732   0.        ]\n",
            " [0.         0.008774   0.        ]]\n",
            "\n",
            "\n",
            "\\Testing: [[1.         0.034107   0.        ]\n",
            " [1.         0.56184602 1.        ]\n",
            " [1.         0.92348999 1.        ]\n",
            " [1.         0.042858   0.        ]\n",
            " [1.         0.47716799 0.        ]\n",
            " [0.         0.031216   0.        ]\n",
            " [1.         0.107955   0.        ]\n",
            " [1.         0.010324   0.        ]\n",
            " [0.         0.58551699 1.        ]\n",
            " [1.         0.032103   0.        ]\n",
            " [1.         0.69247597 1.        ]\n",
            " [0.         0.98558199 1.        ]\n",
            " [1.         0.31789899 0.        ]\n",
            " [1.         0.230019   0.        ]\n",
            " [0.         0.58516997 1.        ]\n",
            " [1.         0.15678801 0.        ]\n",
            " [1.         0.36580399 0.        ]\n",
            " [0.         0.777026   1.        ]\n",
            " [1.         0.07829    0.        ]\n",
            " [0.         0.73868001 1.        ]\n",
            " [0.         0.83762801 1.        ]\n",
            " [0.         0.85616797 1.        ]\n",
            " [1.         0.38984999 0.        ]\n",
            " [1.         0.87457198 1.        ]\n",
            " [1.         0.038507   0.        ]\n",
            " [0.         0.04676    0.        ]\n",
            " [0.         0.225614   0.        ]\n",
            " [0.         0.22847199 0.        ]\n",
            " [0.         0.37850001 0.        ]\n",
            " [0.         0.018892   0.        ]\n",
            " [0.         0.038532   0.        ]\n",
            " [1.         0.53316402 1.        ]\n",
            " [1.         0.90772098 1.        ]\n",
            " [1.         0.97732401 1.        ]\n",
            " [0.         0.26215801 0.        ]\n",
            " [1.         0.45182699 0.        ]\n",
            " [0.         0.345447   0.        ]\n",
            " [1.         0.635818   1.        ]\n",
            " [0.         0.42450699 0.        ]\n",
            " [0.         0.76417202 1.        ]]\n",
            "Training loss:   151.215998\n",
            "\n",
            "\n",
            "\n",
            "Training: labels: [[0.         0.98822498 1.        ]\n",
            " [1.         0.90989798 1.        ]\n",
            " [1.         0.36330301 0.        ]\n",
            " [0.         0.42817599 0.        ]\n",
            " [0.         0.71809399 1.        ]\n",
            " [1.         0.48788601 0.        ]\n",
            " [1.         0.24440099 0.        ]\n",
            " [0.         0.381037   0.        ]\n",
            " [1.         0.36072701 0.        ]\n",
            " [1.         0.099525   0.        ]\n",
            " [0.         0.029445   0.        ]\n",
            " [0.         0.266855   0.        ]\n",
            " [0.         0.38849899 0.        ]\n",
            " [0.         0.84606898 1.        ]\n",
            " [1.         0.91262001 1.        ]\n",
            " [1.         0.813582   1.        ]\n",
            " [0.         0.27027899 0.        ]\n",
            " [0.         0.26119801 0.        ]\n",
            " [1.         0.19002201 0.        ]\n",
            " [0.         0.75665498 1.        ]]\n",
            "\n",
            "\n",
            "\\Testing: [[1.         0.66781002 1.        ]\n",
            " [1.         0.62379301 1.        ]\n",
            " [1.         0.35271201 0.        ]\n",
            " [1.         0.55207801 1.        ]\n",
            " [1.         0.66055697 1.        ]\n",
            " [0.         0.744766   1.        ]\n",
            " [1.         0.52668202 1.        ]\n",
            " [1.         0.414552   0.        ]\n",
            " [0.         0.58699101 1.        ]\n",
            " [1.         0.917988   1.        ]\n",
            " [1.         0.41401201 0.        ]\n",
            " [0.         0.423985   0.        ]\n",
            " [1.         0.295113   0.        ]\n",
            " [1.         0.54870099 1.        ]\n",
            " [0.         0.40243301 0.        ]\n",
            " [1.         0.337071   0.        ]\n",
            " [1.         0.587291   1.        ]\n",
            " [0.         0.25838301 0.        ]\n",
            " [1.         0.59363401 1.        ]\n",
            " [0.         0.73858798 1.        ]\n",
            " [0.         0.673931   1.        ]\n",
            " [0.         0.837717   1.        ]\n",
            " [1.         0.72862601 1.        ]\n",
            " [1.         0.75744301 1.        ]\n",
            " [1.         0.77946502 1.        ]\n",
            " [0.         0.929461   1.        ]\n",
            " [0.         0.81092298 1.        ]\n",
            " [0.         0.41123599 0.        ]\n",
            " [0.         0.78548998 1.        ]\n",
            " [0.         0.93656802 1.        ]\n",
            " [0.         0.92985201 1.        ]\n",
            " [1.         0.173352   0.        ]\n",
            " [1.         0.63368303 1.        ]\n",
            " [1.         0.65524697 1.        ]\n",
            " [0.         0.21416099 0.        ]\n",
            " [1.         0.67395502 1.        ]\n",
            " [0.         0.63944101 1.        ]\n",
            " [1.         0.86194998 1.        ]\n",
            " [0.         0.25828499 0.        ]\n",
            " [0.         0.32865101 0.        ]]\n",
            "Training loss:   148.594478\n",
            "\n",
            "\n",
            "\n",
            "Training: labels: [[0.         0.28375301 0.        ]\n",
            " [1.         0.29833999 0.        ]\n",
            " [1.         0.51750797 1.        ]\n",
            " [0.         0.637514   1.        ]\n",
            " [0.         0.59487897 1.        ]\n",
            " [1.         0.49966699 0.        ]\n",
            " [1.         0.22915301 0.        ]\n",
            " [0.         0.30410001 0.        ]\n",
            " [1.         0.341831   0.        ]\n",
            " [1.         0.77603799 1.        ]\n",
            " [0.         0.37371501 0.        ]\n",
            " [0.         0.75353301 1.        ]\n",
            " [0.         0.584589   1.        ]\n",
            " [0.         0.65721202 1.        ]\n",
            " [1.         0.44507399 0.        ]\n",
            " [1.         0.63305497 1.        ]\n",
            " [0.         0.31692001 0.        ]\n",
            " [0.         0.367185   0.        ]\n",
            " [1.         0.34486499 0.        ]\n",
            " [0.         0.405058   0.        ]]\n",
            "\n",
            "\n",
            "\\Testing: [[1.         0.234284   0.        ]\n",
            " [1.         0.181694   0.        ]\n",
            " [1.         0.227412   0.        ]\n",
            " [1.         0.442552   0.        ]\n",
            " [1.         0.53723902 1.        ]\n",
            " [0.         0.54105699 1.        ]\n",
            " [1.         0.880597   1.        ]\n",
            " [1.         0.64963299 1.        ]\n",
            " [0.         0.58129197 1.        ]\n",
            " [1.         0.31883001 0.        ]\n",
            " [1.         0.52604198 1.        ]\n",
            " [0.         0.885176   1.        ]\n",
            " [1.         0.37370399 0.        ]\n",
            " [1.         0.13618299 0.        ]\n",
            " [0.         0.48189399 0.        ]\n",
            " [1.         0.423978   0.        ]\n",
            " [1.         0.87661099 1.        ]\n",
            " [0.         0.78056997 1.        ]\n",
            " [1.         0.394793   0.        ]\n",
            " [0.         0.210097   0.        ]\n",
            " [0.         0.15750401 0.        ]\n",
            " [0.         0.44345501 0.        ]\n",
            " [1.         0.783737   1.        ]\n",
            " [1.         0.31801701 0.        ]\n",
            " [1.         0.642452   1.        ]\n",
            " [0.         0.35778701 0.        ]\n",
            " [0.         0.44100001 0.        ]\n",
            " [0.         0.719881   1.        ]\n",
            " [0.         0.55284202 1.        ]\n",
            " [0.         0.713754   1.        ]\n",
            " [0.         0.81412202 1.        ]\n",
            " [1.         0.70670003 1.        ]\n",
            " [1.         0.681813   1.        ]\n",
            " [1.         0.569076   1.        ]\n",
            " [0.         0.81291401 1.        ]\n",
            " [1.         0.652614   1.        ]\n",
            " [0.         0.46258599 0.        ]\n",
            " [1.         0.20862199 0.        ]\n",
            " [0.         0.62570798 1.        ]\n",
            " [0.         0.371003   0.        ]]\n",
            "Training loss:   146.499089\n",
            "\n",
            "\n",
            "\n",
            "Training: labels: [[0.         0.147991   0.        ]\n",
            " [1.         0.754879   1.        ]\n",
            " [1.         0.63449198 1.        ]\n",
            " [0.         0.42418399 0.        ]\n",
            " [0.         0.49635199 0.        ]\n",
            " [1.         0.652385   1.        ]\n",
            " [1.         0.354229   0.        ]\n",
            " [0.         0.35373101 0.        ]\n",
            " [1.         0.212865   0.        ]\n",
            " [1.         0.29302099 0.        ]\n",
            " [0.         0.39209801 0.        ]\n",
            " [0.         0.39232999 0.        ]\n",
            " [0.         0.45424899 0.        ]\n",
            " [0.         0.44827601 0.        ]\n",
            " [1.         0.20430499 0.        ]\n",
            " [1.         0.40742001 0.        ]\n",
            " [0.         0.556885   1.        ]\n",
            " [0.         0.29223901 0.        ]\n",
            " [1.         0.341443   0.        ]\n",
            " [0.         0.349675   0.        ]]\n",
            "\n",
            "\n",
            "\\Testing: [[1.         0.401333   0.        ]\n",
            " [1.         0.53566402 1.        ]\n",
            " [1.         0.489328   0.        ]\n",
            " [1.         0.43852201 0.        ]\n",
            " [1.         0.42883301 0.        ]\n",
            " [0.         0.629264   1.        ]\n",
            " [1.         0.47426599 0.        ]\n",
            " [1.         0.48373201 0.        ]\n",
            " [0.         0.534114   1.        ]\n",
            " [1.         0.167594   0.        ]\n",
            " [1.         0.433166   0.        ]\n",
            " [0.         0.47264901 0.        ]\n",
            " [1.         0.49497801 0.        ]\n",
            " [1.         0.50020599 1.        ]\n",
            " [0.         0.46568501 0.        ]\n",
            " [1.         0.64733702 1.        ]\n",
            " [1.         0.67490703 1.        ]\n",
            " [0.         0.59031498 1.        ]\n",
            " [1.         0.62478602 1.        ]\n",
            " [0.         0.64578199 1.        ]\n",
            " [0.         0.33693501 0.        ]\n",
            " [0.         0.363637   0.        ]\n",
            " [1.         0.41903999 0.        ]\n",
            " [1.         0.722857   1.        ]\n",
            " [1.         0.74088299 1.        ]\n",
            " [0.         0.56767499 1.        ]\n",
            " [0.         0.113965   0.        ]\n",
            " [0.         0.32227799 0.        ]\n",
            " [0.         0.40587801 0.        ]\n",
            " [0.         0.40312001 0.        ]\n",
            " [0.         0.213302   0.        ]\n",
            " [1.         0.44316    0.        ]\n",
            " [1.         0.666282   1.        ]\n",
            " [1.         0.455033   0.        ]\n",
            " [0.         0.86745799 1.        ]\n",
            " [1.         0.39915401 0.        ]\n",
            " [0.         0.55461001 1.        ]\n",
            " [1.         0.450894   0.        ]\n",
            " [0.         0.223637   0.        ]\n",
            " [0.         0.526577   1.        ]]\n",
            "Training loss:   144.64229\n",
            "\n",
            "\n",
            "\n",
            "Training: labels: [[0.         0.308469   0.        ]\n",
            " [1.         0.53745699 1.        ]\n",
            " [1.         0.39290699 0.        ]\n",
            " [0.         0.412177   0.        ]\n",
            " [0.         0.116539   0.        ]\n",
            " [1.         0.33340201 0.        ]\n",
            " [1.         0.41267601 0.        ]\n",
            " [0.         0.228515   0.        ]\n",
            " [1.         0.191397   0.        ]\n",
            " [1.         0.192229   0.        ]\n",
            " [0.         0.39919001 0.        ]\n",
            " [0.         0.49659801 0.        ]\n",
            " [0.         0.40402201 0.        ]\n",
            " [0.         0.31128299 0.        ]\n",
            " [1.         0.30400199 0.        ]\n",
            " [1.         0.73625302 1.        ]\n",
            " [0.         0.62572998 1.        ]\n",
            " [0.         0.52060097 1.        ]\n",
            " [1.         0.56666499 1.        ]\n",
            " [0.         0.31534001 0.        ]]\n",
            "\n",
            "\n",
            "\\Testing: [[1.         0.74187797 1.        ]\n",
            " [1.         0.41986001 0.        ]\n",
            " [1.         0.41397399 0.        ]\n",
            " [1.         0.68365699 1.        ]\n",
            " [1.         0.88617998 1.        ]\n",
            " [0.         0.512016   1.        ]\n",
            " [1.         0.78384298 1.        ]\n",
            " [1.         0.77616501 1.        ]\n",
            " [0.         0.45807001 0.        ]\n",
            " [1.         0.60673797 1.        ]\n",
            " [1.         0.19475301 0.        ]\n",
            " [0.         0.21159799 0.        ]\n",
            " [1.         0.78203398 1.        ]\n",
            " [1.         0.377455   0.        ]\n",
            " [0.         0.66751403 1.        ]\n",
            " [1.         0.68861997 1.        ]\n",
            " [1.         0.40377799 0.        ]\n",
            " [0.         0.42630801 0.        ]\n",
            " [1.         0.397416   0.        ]\n",
            " [0.         0.171416   0.        ]\n",
            " [0.         0.33278701 0.        ]\n",
            " [0.         0.32912999 0.        ]\n",
            " [1.         0.559003   1.        ]\n",
            " [1.         0.61396301 1.        ]\n",
            " [1.         0.96161699 1.        ]\n",
            " [0.         0.63315499 1.        ]\n",
            " [0.         0.66286898 1.        ]\n",
            " [0.         0.72099602 1.        ]\n",
            " [0.         0.62847602 1.        ]\n",
            " [0.         0.41679999 0.        ]\n",
            " [0.         0.29032299 0.        ]\n",
            " [1.         0.119685   0.        ]\n",
            " [1.         0.16972101 0.        ]\n",
            " [1.         0.41820699 0.        ]\n",
            " [0.         0.39417899 0.        ]\n",
            " [1.         0.62556899 1.        ]\n",
            " [0.         0.58146101 1.        ]\n",
            " [1.         0.77340698 1.        ]\n",
            " [0.         0.75458199 1.        ]\n",
            " [0.         0.206322   0.        ]]\n",
            "Training loss:   142.99968\n",
            "\n",
            "\n",
            "\n",
            "Training: labels: [[0.         0.49544799 0.        ]\n",
            " [1.         0.454824   0.        ]\n",
            " [1.         0.368947   0.        ]\n",
            " [0.         0.42372999 0.        ]\n",
            " [0.         0.43214399 0.        ]\n",
            " [1.         0.35948899 0.        ]\n",
            " [1.         0.30341601 0.        ]\n",
            " [0.         0.56497598 1.        ]\n",
            " [1.         0.527583   1.        ]\n",
            " [1.         0.50977898 1.        ]\n",
            " [0.         0.38799199 0.        ]\n",
            " [0.         0.72835898 1.        ]\n",
            " [0.         0.306981   0.        ]\n",
            " [0.         0.17659201 0.        ]\n",
            " [1.         0.64197201 1.        ]\n",
            " [1.         0.194169   0.        ]\n",
            " [0.         0.74116403 1.        ]\n",
            " [0.         0.86532998 1.        ]\n",
            " [1.         0.484492   0.        ]\n",
            " [0.         0.307253   0.        ]]\n",
            "\n",
            "\n",
            "\\Testing: [[1.         0.75958401 1.        ]\n",
            " [1.         0.366797   0.        ]\n",
            " [1.         0.44974101 0.        ]\n",
            " [1.         0.426723   0.        ]\n",
            " [1.         0.53932601 1.        ]\n",
            " [0.         0.403382   0.        ]\n",
            " [1.         0.319314   0.        ]\n",
            " [1.         0.22690199 0.        ]\n",
            " [0.         0.58882397 1.        ]\n",
            " [1.         0.52821702 1.        ]\n",
            " [1.         0.46051699 0.        ]\n",
            " [0.         0.297268   0.        ]\n",
            " [1.         0.262761   0.        ]\n",
            " [1.         0.50352502 1.        ]\n",
            " [0.         0.93762499 1.        ]\n",
            " [1.         0.748092   1.        ]\n",
            " [1.         0.861871   1.        ]\n",
            " [0.         0.60802603 1.        ]\n",
            " [1.         0.31060299 0.        ]\n",
            " [0.         0.552872   1.        ]\n",
            " [0.         0.68455201 1.        ]\n",
            " [0.         0.62704903 1.        ]\n",
            " [1.         0.423484   0.        ]\n",
            " [1.         0.306678   0.        ]\n",
            " [1.         0.852323   1.        ]\n",
            " [0.         0.83524299 1.        ]\n",
            " [0.         0.44623199 0.        ]\n",
            " [0.         0.44633499 0.        ]\n",
            " [0.         0.30616301 0.        ]\n",
            " [0.         0.46576399 0.        ]\n",
            " [0.         0.455293   0.        ]\n",
            " [1.         0.51188397 1.        ]\n",
            " [1.         0.45513901 0.        ]\n",
            " [1.         0.49030101 0.        ]\n",
            " [0.         0.34922501 0.        ]\n",
            " [1.         0.42194    0.        ]\n",
            " [0.         0.34827301 0.        ]\n",
            " [1.         0.51208901 1.        ]\n",
            " [0.         0.36844999 0.        ]\n",
            " [0.         0.297414   0.        ]]\n",
            "saving model\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q4e-2Rbyulye",
        "colab_type": "code",
        "outputId": "ce5aaddc-15ae-4742-f291-447a3e785446",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "source": [
        "from matplotlib import pyplot as plt\n",
        "plt.plot(trainingLoss[5:])\n",
        "#plt.plot(testloss)\n",
        "plt.title('Loss')\n",
        "plt.ylabel('Trainging and test') \n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ukOyzcmupeG",
        "colab_type": "code",
        "outputId": "1b251afe-600d-4771-b6c5-92caaecb9886",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "source": [
        "from matplotlib import pyplot as plt\n",
        "#plt.plot(trainingLoss[5:])\n",
        "plt.plot(testloss)\n",
        "plt.title('Loss')\n",
        "plt.ylabel('Trainging and test') \n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZEAAAEWCAYAAACnlKo3AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAgAElEQVR4nO3de7xcVX338c/3XJNMAjlzCBQJmFAj5VJFCBCFKg9YDHgBKyKIEBGNPkCLtVax2saitKhtVfoIyCUtKFdRCioKAcTWVw0QEJFLJAFBgkBCbuSec/k9f+w1J5OTOSeTOWdmcs5836/XvGbP2mvv/ZvJzPll77XXWooIzMzMKtFU7wDMzGzkchIxM7OKOYmYmVnFnETMzKxiTiJmZlYxJxEzM6uYk4iZmVXMScSsSiQ9K+nt9Y7DrJqcRMzMrGJOImY1JKld0jck/SE9viGpPa3bTdKPJK2StELS/0hqSus+K+kFSWsk/VbSsfV9J2aZlnoHYNZgPg/MAA4GArgN+ALw98DfAEuASanuDCAk7QecBxwWEX+QNAVorm3YZqX5TMSstk4HLoyIpRGxDPhH4Iy0rgvYE3htRHRFxP9ENrhdD9AOHCCpNSKejYin6xK9WT9OIma19RrguaLXz6UygK8Bi4G7JD0j6QKAiFgMfBL4IrBU0o2SXoPZTsBJxKy2/gC8tuj1PqmMiFgTEX8TEfsC7wE+VWj7iIjrI+KotG0AX6lt2GalOYmYVVerpDGFB3AD8AVJkyTtBvwD8F0ASe+S9DpJAlaTXcbqlbSfpGNSA/xGYAPQW5+3Y7Y1JxGz6rqD7I9+4TEGWAA8CvwGeBj4cqo7DbgbWAv8Erg0In5G1h5yMfAK8BKwO/C52r0Fs4HJk1KZmVmlfCZiZmYVcxIxM7OKOYmYmVnFnETMzKxiDTfsyW677RZTpkypdxhmZiPKQw899EpETOpf3nBJZMqUKSxYsKDeYZiZjSiSnitVXrXLWZLmSloq6bGisq9JWijpUUm3SppYtO5zkhanEUrfUVQ+M5UtLgwDkcqnSro/ld8kqa1a78XMzEqrZpvIfwIz+5XNAw6KiDcAT5E6TEk6ADgVODBtc6mkZknNwLeA44EDgNNSXciGffh6RLwOWAmcXcX3YmZmJVQtiUTEfwMr+pXdFRHd6eV8YHJaPhG4MSI2RcTvyAahOzw9FkfEMxGxGbgRODENC3EMcEva/hrgpGq9FzMzK62ebSIfAW5Ky3uRJZWCJakM4Pl+5UcAncCqooRUXH8bkmYDswH22WefbdZ3dXWxZMkSNm7cuOPvYgQZM2YMkydPprW1td6hmNkoUZckIunzQDdwXS2OFxFXAFcATJ8+fZtxXpYsWcKECROYMmUK2UnO6BMRLF++nCVLljB16tR6h2Nmo0TN+4lI+jDwLuD02DJw1wvA3kXVJqeygcqXAxMltfQrr8jGjRvp7OwctQkEQBKdnZ2j/mzLzGqrpklE0kzgM8B7ImJ90arbgVPT/NNTyUYzfQB4EJiW7sRqI2t8vz0ln58BJ6ftZ5FNMzqU2Iay+YjQCO/RzGqrmrf43kA2nPV+kpZIOhv4f8AEYJ6kRyRdDhARjwM3A08APwXOjYie1OZxHnAn8CRwc6oL8FmySXsWk7WRXF2t9wLwytpNrFq/uZqHMDMbcarWJhIRp5UoHvAPfURcBFxUovwOsjkZ+pc/Q3b3Vk2sWLeZtuYmJo4b/u4oq1at4vrrr+ecc87Zoe1OOOEErr/+eiZOnLj9ymZmVeCxs8rU0iS6e6sz98qqVau49NJLtynv7u4uUXuLO+64wwnEzOqq4YY9qVRLk9jQ1VOVfV9wwQU8/fTTHHzwwbS2tjJmzBg6OjpYuHAhTz31FCeddBLPP/88Gzdu5Pzzz2f27NnAliFc1q5dy/HHH89RRx3F//7v/7LXXntx2223MXbs2KrEa2ZW4CTSzz/+8HGe+MOr25Rv7u6lu7eXcW07/pEd8JpdmPPuAwdcf/HFF/PYY4/xyCOPcN999/HOd76Txx57rO9W3Llz55LP59mwYQOHHXYY73vf++js7NxqH4sWLeKGG27gyiuv5JRTTuH73/8+H/rQh3Y4VjOzHeEkUiYJajWT8OGHH75VX45LLrmEW2+9FYDnn3+eRYsWbZNEpk6dysEHHwzAoYceyrPPPlubYM2soTmJ9DPQGcPytZt4YdUG9t9zF1qbq9uUlMvl+pbvu+8+7r77bn75y18ybtw4jj766JJ9Pdrb2/uWm5ub2bBhQ1VjNDMDN6yXraUp62PR3TP8pyMTJkxgzZo1JdetXr2ajo4Oxo0bx8KFC5k/f37JemZm9eAzkTI1N2X5tqe3F2ge1n13dnZy5JFHctBBBzF27Fj22GOPvnUzZ87k8ssvZ//992e//fZjxowZw3psM7OhUNTqQv9OYvr06dF/Uqonn3yS/ffff9DtNnb18NTLa9gnP64qfUVqpZz3ambWn6SHImJ6/3JfzipTc+FyVpX6ipiZjUROImVqcRIxM9uGk0iyvct6kmhpEj09vTWKaPg12qVLM6s+JxGyyZqWL1++3T+yzU1NI/ZMpDCfyJgxY+odipmNIr47C5g8eTJLlixh2bJlg9ZbtmYTAOuXtg9ab2dVmNnQzGy4OIkAra2tZc32943vLOB3r6zjrr9+Ww2iMjPb+fly1g7I59pZsc5zipiZFTiJ7IDOXBsr13fRO0LbRczMhpuTyA7oyLXR0xus3tBV71DMzHYKTiI7oDOX9VRf4WlyzcwAJ5Edki8kEbeLmJkBTiI7pJBElq91EjEzAyeRHdI53mciZmbFnER2QMe4QhLZVOdIzMx2Dk4iO2BMazO5tmZWrPPdWWZm4CSyw/Lj23wmYmaWOInsoHyuneVuEzEzA6qYRCTNlbRU0mNFZXlJ8yQtSs8dqVySLpG0WNKjkg4p2mZWqr9I0qyi8kMl/SZtc4kkVeu9FOvMtblh3cwsqeaZyH8CM/uVXQDcExHTgHvSa4DjgWnpMRu4DLKkA8wBjgAOB+YUEk+q87Gi7fofqyo6xjmJmJkVVC2JRMR/Ayv6FZ8IXJOWrwFOKiq/NjLzgYmS9gTeAcyLiBURsRKYB8xM63aJiPmRTQJybdG+qqpzfJZEPMGTmVnt20T2iIgX0/JLwB5peS/g+aJ6S1LZYOVLSpSXJGm2pAWSFmxvzpDtyefa2NTdy/rNPUPaj5nZaFC3hvV0BlGT/85HxBURMT0ipk+aNGlI+/LQJ2ZmW9Q6ibycLkWRnpem8heAvYvqTU5lg5VPLlFedYVBGH2HlplZ7ZPI7UDhDqtZwG1F5Wemu7RmAKvTZa87geMkdaQG9eOAO9O6VyXNSHdlnVm0r6rqyLnXuplZQdWmx5V0A3A0sJukJWR3WV0M3CzpbOA54JRU/Q7gBGAxsB44CyAiVkj6EvBgqndhRBQa688huwNsLPCT9Ki6vuHg3WvdzKx6SSQiThtg1bEl6gZw7gD7mQvMLVG+ADhoKDFWIu8zETOzPu6xvoPGt7fQ1tzkNhEzM5xEdpgk8rk2VnhOETMzJ5FKdHjoEzMzwEmkIp25Ns+zbmaGk0hF8j4TMTMDnEQq4jYRM7OMk0gFOnNtrNnUzaZuj59lZo3NSaQC+fFZX5GV7nBoZg3OSaQC+XEehNHMDJxEKuKRfM3MMk4iFegcXxjJ10OfmFljcxKpQD7XDvhMxMzMSaQCu45tpUlOImZmTiIVaG4SE8e5w6GZmZNIhdxr3czMSaRi+Vybh4M3s4bnJFKhTp+JmJk5iVTKl7PMzJxEKpbPtbFq/WZ6eqPeoZiZ1Y2TSIXyuTZ6A1Zv8PhZZta4tptEJLWXU9Zotgx94l7rZta4yjkT+WWZZQ2lM/VaX+55RcysgbUMtELSHwF7AWMlvQlQWrULMK4Gse3UPAijmdkgSQR4B/BhYDLwr2xJImuAv6tuWDu/viTiudbNrIENmEQi4hrgGknvi4jv1zCmEaEj1wrgaXLNrKGV0yYyWdIuylwl6WFJxw3loJL+WtLjkh6TdIOkMZKmSrpf0mJJN0lqS3Xb0+vFaf2Uov18LpX/VtI7hhLTjmpvaWZCe4t7rZtZQysniXwkIl4FjgM6gTOAiys9oKS9gL8CpkfEQUAzcCrwFeDrEfE6YCVwdtrkbGBlKv96qoekA9J2BwIzgUslNVcaVyXy493h0MwaWzlJpNAWcgJwbUQ8XlRWqRayBvsWskb6F4FjgFvS+muAk9Lyiek1af2xkpTKb4yITRHxO2AxcPgQ49oh7rVuZo2unCTykKS7yJLInZImAL2VHjAiXgD+Bfg9WfJYDTwErIqI7lRtCdmdYaTn59O23al+Z3F5iW22Imm2pAWSFixbtqzS0LeR93DwZtbgykkiZwMXAIdFxHqgDTir0gNK6iA7i5gKvAbIkV2OqpqIuCIipkfE9EmTJg3bfn0mYmaNrpwkEsABZO0YkP3RHzOEY74d+F1ELIuILuAHwJHAxHR5C7Lbil9Iyy8AewOk9bsCy4vLS2xTE4U2kQiPn2VmjamcJHIp8GbgtPR6DfCtIRzz98AMSeNS28axwBPAz4CTU51ZwG1p+fb0mrT+3sj+at8OnJru3poKTAMeGEJcO6wz18bmnl7WburefmUzs1FosM6GBUdExCGSfgUQESsLt99WIiLul3QL8DDQDfwKuAL4MXCjpC+nsqvTJlcD35G0GFhBdkcWEfG4pJvJElA3cG5E9FQaVyXyaeiTFes2M2FMay0PbWa2UygniXSlW2cDQNIkhtCwDhARc4A5/YqfocTdVRGxEXj/APu5CLhoKLEMRb7Q4XDdZl7bmatXGGZmdVPO5axLgFuB3SVdBPwC+OeqRjVCFJ+JmJk1ou2eiUTEdZIeImu7EHBSRDxZ9chGgM40fpZ7rZtZo9puEpH0nYg4A1hYoqyheSRfM2t05VzOOrD4RWofObQ64Yws49qaaW9pchIxs4Y1YBJJgxuuAd4g6dX0WAMsZcvttw1NkjscmllDGzCJRMQ/R8QE4GsRsUt6TIiIzoj4XA1j3Kk5iZhZI9vu5SwnjMHlc21uWDezhlVOm4gNojPXxop1m+odhplZXTiJDFE+1+7ZDc2sYQ14i6+k/GAbRsSK4Q9n5MnnWlm3uYeNXT2Maa3pnFhmZnU3WD+Rh8iGOhGwD9lsgwImkg2iOLXq0Y0AhV7rK9dvZs9dx9Y5GjOz2hrs7qypEbEvcDfw7ojYLSI6gXcBd9UqwJ1docPhcl/SMrMGVE6byIyIuKPwIiJ+AryleiGNLJ3j3WvdzBpXOaP4/kHSF4DvptenA3+oXkgji4c+MbNGVs6ZyGnAJLKRfG8FdmfLBFUNr9NJxMwaWDmj+K4Azq9BLCPSLmNaaW6Sk4iZNaRyRvF9PfBpYEpx/Yg4pnphjRxNTaJjXKt7rZtZQyqnTeR7wOXAVUBNp58dKfLutW5mDaqcJNIdEZdVPZIRzIMwmlmjKqdh/YeSzpG0p6R84VH1yEaQzly7k4iZNaRyzkRmpee/LSoLYN/hD2dk6si1OomYWUMq5+4sD2+yHflcO6s2dNHTGzQ3qd7hmJnVTDlnIkg6CDgAGFMoi4hrqxXUSNOZayMiGz9rt/Ht9Q7HzKxmyrnFdw5wNFkSuQM4HvgF4CSSFPdadxIxs0ZSTsP6ycCxwEsRcRbwRmDXqkY1wrjXupk1qnKSyIaI6AW6Je0CLAX2HspBJU2UdIukhZKelPTmdNfXPEmL0nNHqitJl0haLOlRSYcU7WdWqr9I0qyBj1hdHU4iZtagykkiCyRNBK4km2PkYeCXQzzuN4GfRsSfkJ3ZPAlcANwTEdOAe9JryC6fTUuP2cBl0Ddp1hzgCOBwYE4h8dRa4UzEvdbNrNGUc3fWOWnxckk/BXaJiEcrPaCkXYG3Ah9O+98MbJZ0IlnbC8A1wH3AZ4ETgWsjIoD56Sxmz1R3XmGGRUnzgJnADZXGVqm+MxHPKWJmDaasu7MKIuLZYTjmVGAZ8B+S3kh2dnM+sEdEvJjqvATskZb3Ap4v2n5JKhuovOZam5vYZUyLhz4xs4ZTzuWs4dYCHAJcFhFvAtax5dIVAOmsI4brgJJmS1ogacGyZcuGa7db6Rzfzor1XVXZt5nZzqoeSWQJsCQi7k+vbyFLKi+ny1Sk56Vp/Qts3ZA/OZUNVL6NiLgiIqZHxPRJkyYN2xsp1jGu1WciZtZwtptEisfLKnq0VnrAiHgJeF7SfqnoWOAJ4Ha2DLEyC7gtLd8OnJnu0poBrE6Xve4EjpPUkRrUj0tldZHPtXuedTNrOOW0iTxM9j/+lYCAicBLkl4GPhYRD1Vw3L8ErpPUBjwDnEWW0G6WdDbwHHBKqnsHcAKwGFif6hIRKyR9CXgw1buw0MheD525Nh5dsqpehzczq4tyksg84JaIuBNA0nHA+4D/AC4lu8V2h0TEI8D0EquOLVE3gHMH2M9cYO6OHr8a8uPbWLl+MxGB5PGzzKwxlNMmMqOQQAAi4i7gzRExH/AYH0lnro2unmDNpu56h2JmVjPlJJEXJX1W0mvT4zNkjeDNQG+V4xsxOsa5r4iZNZ5yksgHye58+q/02CeVNbOl3aLh5ce717qZNZ5yeqy/QtYQXsri4Q1n5PIgjGbWiMoZCv71wKeBKcX1I+KY6oU18mwZDt59RcyscZRzd9b3gMuBq4Ce6oYzcnXmsnsMVqxzr3UzaxzlJJHuiLis6pGMcGPbmhnT2uQzETNrKOU0rP9Q0jmS9izutV71yEagzly7G9bNrKGUcyZSGIrkb4vKAth3+MMZ2fK5Njesm1lDKefurKm1CGQ0cBIxs0YzYBKRdExE3CvpL0qtj4gfVC+skakz18bTy9bWOwwzs5oZ7EzkbcC9wLtLrAvASaSfDp+JmFmDGTCJRMSc9HxW7cIZ2fK5NtZv7mFjVw9jWpvrHY6ZWdWV09nwUyWKVwMPpdF4LSn0Wl++bjN7TRxb52jMzKqvnFt8pwOfYMu85h8HZgJXpsEYLenrte5BGM2sQZRzi+9k4JCIWAsgaQ7wY+CtwEPAV6sX3sjSmQZhXLHeScTMGkM5ZyK7A8XdsLuAPSJiQ7/yhpfvG/rEH4uZNYZyzkSuA+6XVJjz/N3A9ZJyZHOjW5JPc4p4rnUzaxTldDb8kqSfAm9JRZ+IiAVp+fSqRTYC7TK2hZYm+TZfM2sY5ZyJADwMvFCoL2mfiPh91aIaoSS5r4iZNZRybvH9S2AO8DLZUPAi62z4huqGNjJ1OomYWQMp50zkfGC/iFhe7WBGA4+fZWaNpJy7s54n61xoZfDlLDNrJOWciTwD3CfpxxTd0hsR/1a1qEawzlyb5xQxs4ZRThL5fXq0pYcNIp9rY/WGLrp6emltLudEz8xs5CrnFt9/rEUgo0Vh/KxV67uYNKG9ztGYmVXXgP9VlvSN9PxDSbf3fwz1wJKaJf1K0o/S66mS7pe0WNJNktpSeXt6vTitn1K0j8+l8t9KesdQYxoOW3qt+5KWmY1+g52JfCc9/0uVjn0+8CSwS3r9FeDrEXGjpMuBs4HL0vPKiHidpFNTvQ9IOgA4FTgQeA1wt6TXR0RPleItS0euFYDl6zYBE+oZiplZ1Q14JhIRD6Xnn5d6DOWgkiYD7wSuSq8FHAPckqpcA5yUlk9Mr0nrj031TwRujIhNEfE7YDFw+FDiGg6dPhMxsway3ZZfSdMk3SLpCUnPFB5DPO43gM8Avel1J7AqIrrT6yVkw86Tnp8HSOtXp/p95SW26f8eZktaIGnBsmXLhhj64PqGg3cSMbMGUM7tQ/9BdlmpG/g/wLXAdys9oKR3AUsLZzq1EBFXRMT0iJg+adKkqh6rY1x2OctJxMwaQTlJZGxE3AMoIp6LiC+SXYqq1JHAeyQ9C9xIdhnrm8BESYU2mslkY3WRnvcGSOt3BZYXl5fYpm5ampuYOK7VScTMGkI5SWSTpCZgkaTzJL0XGF/pASPicxExOSKmkDWM3xsRpwM/A05O1WYBhaHnb0+vSevvjYhI5aemu7emAtOAByqNazjlx7nDoZk1hnKSyPnAOOCvgEOBD7Hlj/pw+izwKUmLydo8rk7lVwOdqfxTwAUAEfE4cDPZnCY/Bc6t951ZBflcm6fINbOGMGhnQ0nNwAci4tPAWuCs4Tx4RNwH3JeWn6HE3VURsRF4/wDbXwRcNJwxDYd8ro3nlq+vdxhmZlU3WGfDlvQ/+6NqGM+o0Dm+zfOsm1lDGOxM5AHgEOBXqYf694B1hZUR8YMqxzZi5XNtrFy3mYgg69JiZjY6lTMA4xiyu6GOIZuMqjAplZPIADrGtdHdG7y6oZtd0y2/Zmaj0WBJZHdJnwIeY0vyKIiqRjXCdY7POhwuX7fJScTMRrXBkkgz2a28pa7HOIkMongQxn2r27fRzKyuBksiL0bEhTWLZBTp9NAnZtYgBusn4hbhCnn8LDNrFIMlkWNrFsUoU0gi7rVuZqPdYEPBr6hlIKPJmNZmxrU1+0zEzEY9TwJeJflcm5OImY16TiJV0ukkYmYNwEmkSnwmYmaNwEmkSjqcRMysATiJVElnro3l6zbVOwwzs6pyEqmSfK6djV29rN/cvf3KZmYjlJNIlbjXupk1AieRKnGvdTNrBE4iVdLhXutm1gCcRKqk73KW51o3s1HMSaRK8uN9OcvMRj8nkSqZ0N5Ca7M817qZjWpOIlUiKeu17stZZjaKOYlUUT7X7oZ1MxvVnESqKJ9rZYV7rZvZKOYkUkX5XLsb1s1sVKt5EpG0t6SfSXpC0uOSzk/leUnzJC1Kzx2pXJIukbRY0qOSDina16xUf5GkWbV+L9vj4eDNbLSrx5lIN/A3EXEAMAM4V9IBwAXAPRExDbgnvQY4HpiWHrOByyBLOsAc4AjgcGBOIfHsLPK5Nl7d2E1XT2+9QzEzq4qaJ5GIeDEiHk7La4Angb2AE4FrUrVrgJPS8onAtZGZD0yUtCfwDmBeRKyIiJXAPGBmDd/KdhWGPlnpsxEzG6Xq2iYiaQrwJuB+YI+IeDGtegnYIy3vBTxftNmSVDZQeanjzJa0QNKCZcuWDVv825P30CdmNsrVLYlIGg98H/hkRLxavC4iAojhOlZEXBER0yNi+qRJk4Zrt9vlQRjNbLSrSxKR1EqWQK6LiB+k4pfTZSrS89JU/gKwd9Hmk1PZQOU7DQ8Hb2ajXT3uzhJwNfBkRPxb0arbgcIdVrOA24rKz0x3ac0AVqfLXncCx0nqSA3qx6WynYbPRMxstGupwzGPBM4AfiPpkVT2d8DFwM2SzgaeA05J6+4ATgAWA+uBswAiYoWkLwEPpnoXRsSK2ryF8kwc14bkNhEzG71qnkQi4heABlh9bIn6AZw7wL7mAnOHL7rh1dwkJo51r3UzG73cY73K8u5waGajmJNIlXV66BMzG8WcRKrMZyJmNpo5iVRZfryTiJmNXk4iVZYf18bK9V309g5b30kzs52Gk0iV5XNt9PQGqzd01TsUM7Nh5yRSZZ3jU4dDz7VuZqOQk0iVude6mY1mTiJV1jeS71onETMbfZxEqmw4zkS6enr5wn/9hq/+dKEb6M1sp1KPsbMaypYkUtnQJxu7ejjv+oe5+8lsUOOV67u46KSDaGoaaOQYM7PacRKpsvaWZsa3t7Bi3Y7fnbVhcw+zv7OA/1n0Cl866SBeXLWBS+97mojgn977p04kZlZ3TiI1kPVa37EzkbWbuvnoNQ9y/+9W8NWT38Ap0/cmImhuEv9+72J6eoOL3/cGmp1IzKyOnERqIJ9r26Hh4F/d2MWH5z7Ar5es5hsfOJgTD85m/ZXEp/789TRJfPOeRfQGfPVkJxIzqx8nkRrI59p4+dWNZdVduW4zZ859gIUvvcq3PvgmZh6051brJfHXKZF8/e6niAi+9v43OpGYWV04idRAPtfGky++ut16y9Zs4oyr7+eZV9bx7TMO5Zg/2WPAuue/fRrNTfAvdz1FTwT/+v430tLsm+3MrLacRGqgM43kGxFkswNv66XVGzn9qvm8sGoDc2cdxlHTdtvufs87ZhpNTeKrP/0tvQFfP8WJxMxqy0mkBvK5NjZ197J+cw+59m0/8iUr1/PBK+9n+dpNXPuRIzh8ar7sfZ9z9Otolvjnn2R9SL5x6sG0OpGYWY04idRAcYfD/knk2VfWcfpV97NmYxff/egRvGmfjh3e/8ff9sc0N4kv//hJeiO45LQ3OZGYWU34L00N9A190u8OrcVL13DKt3/J+s3dXP+xGRUlkIKP/tm+/P27DuAnj73Eedc/zObu3iHFbGZWDieRGijVa/2JP7zKB749n96Amz7+Zg7aa9chH+fso6Yy590HcOfjL3OuE4mZ1YCTSA105toB+nqtP7pkFaddOZ+2liZu/vgMXr/HhGE71llHTuXCEw9k3hMv83+/+xCbunuGbd9mZv05idRAfvyWM5GHnlvB6Vfez4QxLdz88Tez76Txw368M988hS+fdBD3LFzKJ77zEBu7nEjMrDqcRGog19ZMW0sT9y5cyhlXP8BuE9q5+eNvZu/8uKod80MzXss/vfdP+dlvl/FxJxIzqxLfnVUDkujMtTH/mRVM23081330CHbfZUzVj/vBI/ahuQku+MFv+Ni1C7jyzOmMaW2u+nFt5xcRbO7pZcPmHjZ09bB+c0/f8obN2euNqXz95m42dvWwuSdolmgSNDWJpsKylF5Dc5NQKs/qCqXywjLQt9wkIUDKfifZcra9BEL91hWVAaTX9K1LdfuWU6V+67eU0hdT8X7YzjqpRNlW2wy0rvxjb3280tuVjG2rHWxdZ7fxbQP2VavUiE8ikmYC3wSagasi4uI6h1TS1N1y5HNtXPuRw+kc316z437gsH1okvjM9x/lwDl3Zj/O7JdX8kdZ+LFS/LrEj2/L91BbfXmLfxRbl2/7xS31Yy1sW6q8sC/67a/0j6Z431teRQQBEBBFryMgiOw5tq671ToK64tfF9UbZP+F91P8Off9gdymfOs/hP3/jfp/Ptv73AV090ZfktjQ1UOP56ZpOAu/NHPY/yM5opOIpGbgW8CfA0uAByXdHhFP1Deybc398GG0NKkuPdRjouIAAAg5SURBVMrfP31vdt9lDPc/s3yrP4pb/aEr+gNZ+IMJ2/4R3GpdUTlbbZP237e8pbyodvGLUotEbP1HrvR+tq2/1Vb9jrl1Ai3+323/BDrAH/FUYXt/4LctL/5s+ietgZLVlqRWXN7/My5+Kv4MYuvVNAvGtrUwtrWZcW3NjG1rZmxr9jyurZkxqXzLckvf+rGtzbQ2iwjojaAnxdYbQU9v0JveR2G5NyI9oLc3+uoVJ+He9N56+75/W7/fwj57t0napb+XFK/f5vPaktz76hdvP8BnWLyOom36ryv9fe/3/S3j2MXb9TvsNtuVirH4d9V/vwAtVRhjb0QnEeBwYHFEPAMg6UbgRGCnSyL1voz0ttdP4m2vn1TXGGzkk6AJjfg/HDZ8RnrD+l7A80Wvl6SyrUiaLWmBpAXLli2rWXBmZqPdSE8iZYmIKyJiekRMnzTJ/xs3MxsuIz2JvADsXfR6ciozM7MaGOlJ5EFgmqSpktqAU4Hb6xyTmVnDGNHtYxHRLek84E6yW3znRsTjdQ7LzKxhjOgkAhARdwB31DsOM7NGNNIvZ5mZWR05iZiZWcXUv1flaCdpGfBchZvvBrwyjOEMN8c3NI5vaBzf0Ozs8b02IrbpI9FwSWQoJC2IiOn1jmMgjm9oHN/QOL6h2dnjG4gvZ5mZWcWcRMzMrGJOIjvminoHsB2Ob2gc39A4vqHZ2eMryW0iZmZWMZ+JmJlZxZxEzMysYk4iJUiaKem3khZLuqDE+nZJN6X190uaUsPY9pb0M0lPSHpc0vkl6hwtabWkR9LjH2oVXzr+s5J+k469oMR6SbokfX6PSjqkhrHtV/S5PCLpVUmf7Fenpp+fpLmSlkp6rKgsL2mepEXpuWOAbWelOoskzaphfF+TtDD9+90qaeIA2w76XahifF+U9ELRv+EJA2w76G+9ivHdVBTbs5IeGWDbqn9+Q5ZNwelH4UE2kOPTwL5AG/Br4IB+dc4BLk/LpwI31TC+PYFD0vIE4KkS8R0N/KiOn+GzwG6DrD8B+AnZzLEzgPvr+G/9Elknqrp9fsBbgUOAx4rKvgpckJYvAL5SYrs88Ex67kjLHTWK7zigJS1/pVR85XwXqhjfF4FPl/HvP+hvvVrx9Vv/r8A/1OvzG+rDZyLb6ptyNyI2A4Upd4udCFyTlm8BjlVhcu0qi4gXI+LhtLwGeJISsznu5E4Ero3MfGCipD3rEMexwNMRUekIBsMiIv4bWNGvuPg7dg1wUolN3wHMi4gVEbESmAfMrEV8EXFXRHSnl/PJ5vKpiwE+v3KU81sfssHiS383TgFuGO7j1oqTyLbKmXK3r076Ia0GOmsSXZF0Ge1NwP0lVr9Z0q8l/UTSgTUNDAK4S9JDkmaXWF/WtMY1cCoD/3jr+fkB7BERL6bll4A9StTZWT7Hj5CdWZayve9CNZ2XLrfNHeBy4M7w+f0Z8HJELBpgfT0/v7I4iYxQksYD3wc+GRGv9lv9MNklmjcC/w78V43DOyoiDgGOB86V9NYaH3+70iRm7wG+V2J1vT+/rUR2XWOnvBdf0ueBbuC6AarU67twGfDHwMHAi2SXjHZGpzH4WchO/1tyEtlWOVPu9tWR1ALsCiyvSXTZMVvJEsh1EfGD/usj4tWIWJuW7wBaJe1Wq/gi4oX0vBS4leyyQbGdYVrj44GHI+Ll/ivq/fklLxcu8aXnpSXq1PVzlPRh4F3A6SnRbaOM70JVRMTLEdETEb3AlQMct96fXwvwF8BNA9Wp1+e3I5xEtlXOlLu3A4U7YU4G7h3oRzTc0jXUq4EnI+LfBqjzR4U2GkmHk/071yTJScpJmlBYJmuAfaxftduBM9NdWjOA1UWXbmplwP8B1vPzK1L8HZsF3Faizp3AcZI60uWa41JZ1UmaCXwGeE9ErB+gTjnfhWrFV9zG9t4Bjlvv6bXfDiyMiCWlVtbz89sh9W7Z3xkfZHcPPUV258bnU9mFZD8YgDFkl0EWAw8A+9YwtqPILm08CjySHicAnwA+keqcBzxOdrfJfOAtNYxv33TcX6cYCp9fcXwCvpU+398A02v875sjSwq7FpXV7fMjS2YvAl1k1+XPJmtjuwdYBNwN5FPd6cBVRdt+JH0PFwNn1TC+xWTtCYXvYOFuxdcAdwz2XahRfN9J361HyRLDnv3jS6+3+a3XIr5U/p+F71xR3Zp/fkN9eNgTMzOrmC9nmZlZxZxEzMysYk4iZmZWMScRMzOrmJOImZlVzEnEbIRIowv/qN5xmBVzEjEzs4o5iZgNM0kfkvRAmgPi25KaJa2V9HVlc8DcI2lSqnuwpPlF83J0pPLXSbo7DQL5sKQ/TrsfL+mWNJfHdbUaPdpsIE4iZsNI0v7AB4AjI+JgoAc4nayX/IKIOBD4OTAnbXIt8NmIeANZD+tC+XXAtyIbBPItZD2eIRu1+ZPAAWQ9mo+s+psyG0RLvQMwG2WOBQ4FHkwnCWPJBk/sZctAe98FfiBpV2BiRPw8lV8DfC+Nl7RXRNwKEBEbAdL+Hog01lKaDW8K8Ivqvy2z0pxEzIaXgGsi4nNbFUp/369epeMNbSpa7sG/YaszX84yG173ACdL2h365kp/Ldlv7eRU54PALyJiNbBS0p+l8jOAn0c2Y+USSSelfbRLGlfTd2FWJv8vxmwYRcQTkr5ANhtdE9nIrecC64DD07qlZO0mkA3zfnlKEs8AZ6XyM4BvS7ow7eP9NXwbZmXzKL5mNSBpbUSMr3ccZsPNl7PMzKxiPhMxM7OK+UzEzMwq5iRiZmYVcxIxM7OKOYmYmVnFnETMzKxi/x8f6XTUBiGk9wAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}